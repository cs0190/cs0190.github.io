<!doctype HTML>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="codemirror.js"></script>
<script src="runmode.js"></script>
<script src="pyret.js"></script>
<script src="hilite.js"></script>
<script src="search.js"></script>
<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=0.8"/><title>3.28&nbsp;tensorflow</title><link rel="stylesheet" type="text/css" href="scribble.css" title="default"/><link rel="stylesheet" type="text/css" href="manual-style.css" title="default"/><link rel="stylesheet" type="text/css" href="manual-racket.css" title="default"/><link rel="stylesheet" type="text/css" href="manual-fonts.css" title="default"/><link rel="stylesheet" type="text/css" href="codemirror.css" title="default"/><link rel="stylesheet" type="text/css" href="pyret.css" title="default"/><link rel="stylesheet" type="text/css" href="styles.css" title="default"/><script type="text/javascript" src="scribble-common.js"></script><script type="text/javascript" src="manual-racket.js"></script><!--[if IE 6]><style type="text/css">.SIEHidden { overflow: hidden; }</style><![endif]--></head><body id="scribble-racket-lang-org"><div class="tocset"><div class="tocview"><div class="tocviewlist tocviewlisttopspace"><div class="tocviewtitle"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_0&quot;);">&#9658;</a></td><td></td><td><a href="index.html" class="tocviewlink" data-pltdoc="x">Pyret</a></td></tr></table></div><div class="tocviewsublisttop" style="display: none;" id="tocview_0"><table cellspacing="0" cellpadding="0"><tr><td align="right">1&nbsp;</td><td><a href="Getting_Started.html" class="tocviewlink" data-pltdoc="x">Getting Started</a></td></tr><tr><td align="right">2&nbsp;</td><td><a href="Language_Concepts.html" class="tocviewlink" data-pltdoc="x">Language Concepts</a></td></tr><tr><td align="right">3&nbsp;</td><td><a href="Builtins_and_Libraries.html" class="tocviewselflink" data-pltdoc="x">Builtins and Libraries</a></td></tr><tr><td align="right">4&nbsp;</td><td><a href="Pyret_Style_Guide.html" class="tocviewlink" data-pltdoc="x">Pyret Style Guide</a></td></tr><tr><td align="right">5&nbsp;</td><td><a href="Internals.html" class="tocviewlink" data-pltdoc="x">Internals</a></td></tr><tr><td align="right">6&nbsp;</td><td><a href="Glossary.html" class="tocviewlink" data-pltdoc="x">Glossary</a></td></tr></table></div></div><div class="tocviewlist"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_1&quot;);">&#9660;</a></td><td>3&nbsp;</td><td><a href="Builtins_and_Libraries.html" class="tocviewlink" data-pltdoc="x">Builtins and Libraries</a></td></tr></table><div class="tocviewsublist" style="display: block;" id="tocview_1"><table cellspacing="0" cellpadding="0"><tr><td align="right">3.1&nbsp;</td><td><a href="_global_.html" class="tocviewlink" data-pltdoc="x">Global Utilities</a></td></tr><tr><td align="right">3.2&nbsp;</td><td><a href="numbers.html" class="tocviewlink" data-pltdoc="x">Numbers</a></td></tr><tr><td align="right">3.3&nbsp;</td><td><a href="strings.html" class="tocviewlink" data-pltdoc="x">Strings</a></td></tr><tr><td align="right">3.4&nbsp;</td><td><a href="booleans.html" class="tocviewlink" data-pltdoc="x">Booleans</a></td></tr><tr><td align="right">3.5&nbsp;</td><td><a href="raw-arrays.html" class="tocviewlink" data-pltdoc="x">Raw<span class="mywbr"> &nbsp;</span>Array</a></td></tr><tr><td align="right">3.6&nbsp;</td><td><a href="tables.html" class="tocviewlink" data-pltdoc="x">Tables</a></td></tr><tr><td align="right">3.7&nbsp;</td><td><a href="lists.html" class="tocviewlink" data-pltdoc="x">lists</a></td></tr><tr><td align="right">3.8&nbsp;</td><td><a href="sets.html" class="tocviewlink" data-pltdoc="x">sets</a></td></tr><tr><td align="right">3.9&nbsp;</td><td><a href="arrays.html" class="tocviewlink" data-pltdoc="x">arrays</a></td></tr><tr><td align="right">3.10&nbsp;</td><td><a href="string-dict.html" class="tocviewlink" data-pltdoc="x">string-<wbr></wbr>dict</a></td></tr><tr><td align="right">3.11&nbsp;</td><td><a href="option.html" class="tocviewlink" data-pltdoc="x">option</a></td></tr><tr><td align="right">3.12&nbsp;</td><td><a href="pick.html" class="tocviewlink" data-pltdoc="x">pick</a></td></tr><tr><td align="right">3.13&nbsp;</td><td><a href="either.html" class="tocviewlink" data-pltdoc="x">either</a></td></tr><tr><td align="right">3.14&nbsp;</td><td><a href="srcloc.html" class="tocviewlink" data-pltdoc="x">srcloc</a></td></tr><tr><td align="right">3.15&nbsp;</td><td><a href="pprint.html" class="tocviewlink" data-pltdoc="x">pprint</a></td></tr><tr><td align="right">3.16&nbsp;</td><td><a href="s-exp.html" class="tocviewlink" data-pltdoc="x">s-<wbr></wbr>exp</a></td></tr><tr><td align="right">3.17&nbsp;</td><td><a href="s-exp-structs.html" class="tocviewlink" data-pltdoc="x">s-<wbr></wbr>exp-<wbr></wbr>structs</a></td></tr><tr><td align="right">3.18&nbsp;</td><td><a href="image-structs.html" class="tocviewlink" data-pltdoc="x">image-<wbr></wbr>structs</a></td></tr><tr><td align="right">3.19&nbsp;</td><td><a href="image.html" class="tocviewlink" data-pltdoc="x">image</a></td></tr><tr><td align="right">3.20&nbsp;</td><td><a href="world.html" class="tocviewlink" data-pltdoc="x">world</a></td></tr><tr><td align="right">3.21&nbsp;</td><td><a href="gdrive-sheets.html" class="tocviewlink" data-pltdoc="x">gdrive-<wbr></wbr>sheets</a></td></tr><tr><td align="right">3.22&nbsp;</td><td><a href="data-source.html" class="tocviewlink" data-pltdoc="x">data-<wbr></wbr>source</a></td></tr><tr><td align="right">3.23&nbsp;</td><td><a href="reactors.html" class="tocviewlink" data-pltdoc="x">reactors</a></td></tr><tr><td align="right">3.24&nbsp;</td><td><a href="chart.html" class="tocviewlink" data-pltdoc="x">chart</a></td></tr><tr><td align="right">3.25&nbsp;</td><td><a href="plot.html" class="tocviewlink" data-pltdoc="x">plot</a></td></tr><tr><td align="right">3.26&nbsp;</td><td><a href="statistics.html" class="tocviewlink" data-pltdoc="x">statistics</a></td></tr><tr><td align="right">3.27&nbsp;</td><td><a href="math.html" class="tocviewlink" data-pltdoc="x">math</a></td></tr><tr><td align="right">3.28&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">tensorflow</a></td></tr></table></div></div><div class="tocviewlist"><table cellspacing="0" cellpadding="0"><tr><td style="width: 1em;"><a href="javascript:void(0);" title="Expand/Collapse" class="tocviewtoggle" onclick="TocviewToggle(this,&quot;tocview_2&quot;);">&#9658;</a></td><td>3.28&nbsp;</td><td><a href="" class="tocviewselflink" data-pltdoc="x">tensorflow</a></td></tr></table><div class="tocviewsublistbottom" style="display: none;" id="tocview_2"><table cellspacing="0" cellpadding="0"><tr><td align="right">3.28.1&nbsp;</td><td><a href="#%28part._.Tensors%29" class="tocviewlink" data-pltdoc="x">Tensors</a></td></tr><tr><td align="right">3.28.2&nbsp;</td><td><a href="#%28part._.Tensor_.Operations%29" class="tocviewlink" data-pltdoc="x">Tensor Operations</a></td></tr><tr><td align="right">3.28.3&nbsp;</td><td><a href="#%28part._.Tensor.Buffers%29" class="tocviewlink" data-pltdoc="x">Tensor<span class="mywbr"> &nbsp;</span>Buffers</a></td></tr><tr><td align="right">3.28.4&nbsp;</td><td><a href="#%28part._.Models%29" class="tocviewlink" data-pltdoc="x">Models</a></td></tr><tr><td align="right">3.28.5&nbsp;</td><td><a href="#%28part._.Symbolic.Tensors%29" class="tocviewlink" data-pltdoc="x">Symbolic<span class="mywbr"> &nbsp;</span>Tensors</a></td></tr><tr><td align="right">3.28.6&nbsp;</td><td><a href="#%28part._.Layers%29" class="tocviewlink" data-pltdoc="x">Layers</a></td></tr><tr><td align="right">3.28.7&nbsp;</td><td><a href="#%28part._.Optimizers%29" class="tocviewlink" data-pltdoc="x">Optimizers</a></td></tr></table></div></div></div><div class="tocsub"><div class="tocsubtitle">On this page:</div><table class="tocsublist" cellspacing="0"><tr><td><span class="tocsublinknumber">3.28.1<tt>&nbsp;</tt></span><a href="#%28part._.Tensors%29" class="tocsubseclink" data-pltdoc="x">Tensors</a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Tensor</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.1.1<tt>&nbsp;</tt></span><a href="#%28part._.Tensor_.Constructors%29" class="tocsubseclink" data-pltdoc="x">Tensor Constructors</a></td></tr><tr><td><a href="#%28part._tensorflow_tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>tensor</span></a></td></tr><tr><td><a href="#%28part._tensorflow_list-to-tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">list-<wbr></wbr>to-<wbr></wbr>tensor</span></a></td></tr><tr><td><a href="#%28part._tensorflow_make-scalar%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>scalar</span></a></td></tr><tr><td><a href="#%28part._tensorflow_fill%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">fill</span></a></td></tr><tr><td><a href="#%28part._tensorflow_linspace%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">linspace</span></a></td></tr><tr><td><a href="#%28part._tensorflow_ones%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">ones</span></a></td></tr><tr><td><a href="#%28part._tensorflow_zeros%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">zeros</span></a></td></tr><tr><td><a href="#%28part._tensorflow_multinomial%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">multinomial</span></a></td></tr><tr><td><a href="#%28part._tensorflow_random-normal%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">random-<wbr></wbr>normal</span></a></td></tr><tr><td><a href="#%28part._tensorflow_random-uniform%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">random-<wbr></wbr>uniform</span></a></td></tr><tr><td><a href="#%28part._tensorflow_make-variable%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>variable</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.1.2<tt>&nbsp;</tt></span><a href="#%28part._.Tensor_.Methods%29" class="tocsubseclink" data-pltdoc="x">Tensor Methods</a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_size%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.size</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.shape</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_flatten%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.flatten</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-scalar%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>scalar</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-1d%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>1d</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-2d%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>2d</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-3d%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>3d</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-4d%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>4d</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_as-type%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.as-<wbr></wbr>type</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_data-now%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.data-<wbr></wbr>now</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_to-float%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>float</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_to-int%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>int</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_to-bool%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>bool</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_to-buffer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>buffer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_to-variable%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>variable</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.reshape</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_expand-dims%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.expand-<wbr></wbr>dims</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_squeeze%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.squeeze</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_clone%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.clone</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_add%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.add</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_subtract%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.subtract</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_multiply%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.multiply</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_divide%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.divide</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_floor-divide%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.floor-<wbr></wbr>divide</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_max%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.max</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_min%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.min</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_modulo%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.modulo</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_expt%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.expt</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor_shared._methods_squared-difference%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.squared-<wbr></wbr>difference</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.2<tt>&nbsp;</tt></span><a href="#%28part._.Tensor_.Operations%29" class="tocsubseclink" data-pltdoc="x">Tensor Operations</a></td></tr><tr><td><span class="tocsublinknumber">3.28.2.1<tt>&nbsp;</tt></span><a href="#%28part._.Arithmetic_.Operations%29" class="tocsubseclink" data-pltdoc="x">Arithmetic Operations</a></td></tr><tr><td><a href="#%28part._tensorflow_add-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">add-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_subtract-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">subtract-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_multiply-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">multiply-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_divide-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">divide-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_floor-divide-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">floor-<wbr></wbr>divide-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-max%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>max</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-min%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>min</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-modulo%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>modulo</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-expt%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>expt</span></a></td></tr><tr><td><a href="#%28part._tensorflow_squared-difference%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">squared-<wbr></wbr>difference</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-add-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>add-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-subtract-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>subtract-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-multiply-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>multiply-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-divide-tensors%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>divide-<wbr></wbr>tensors</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-tensor-max%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>tensor-<wbr></wbr>max</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-tensor-min%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>tensor-<wbr></wbr>min</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-tensor-expt%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>tensor-<wbr></wbr>expt</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-tensor-modulo%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>tensor-<wbr></wbr>modulo</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strict-squared-difference%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strict-<wbr></wbr>squared-<wbr></wbr>difference</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.2.2<tt>&nbsp;</tt></span><a href="#%28part._.Trigonometry_.Operations%29" class="tocsubseclink" data-pltdoc="x">Trigonometry Operations</a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-acos%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>acos</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-acosh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>acosh</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-asin%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>asin</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-asinh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>asinh</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-atan%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>atan</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-atan2%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>atan2</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-atanh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>atanh</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-cos%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>cos</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-cosh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>cosh</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-sin%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>sin</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-sinh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>sinh</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-tan%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>tan</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-tanh%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>tanh</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.2.3<tt>&nbsp;</tt></span><a href="#%28part._.Math_.Operations%29" class="tocsubseclink" data-pltdoc="x">Math Operations</a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-abs%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>abs</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-ceil%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>ceil</span></a></td></tr><tr><td><a href="#%28part._tensorflow_clip-by-value%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">clip-<wbr></wbr>by-<wbr></wbr>value</span></a></td></tr><tr><td><a href="#%28part._tensorflow_exponential-linear-units%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">exponential-<wbr></wbr>linear-<wbr></wbr>units</span></a></td></tr><tr><td><a href="#%28part._tensorflow_elu%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">elu</span></a></td></tr><tr><td><a href="#%28part._tensorflow_gauss-error%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">gauss-<wbr></wbr>error</span></a></td></tr><tr><td><a href="#%28part._tensorflow_erf%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">erf</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-exp%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>exp</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-exp-min1%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>exp-<wbr></wbr>min1</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-floor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>floor</span></a></td></tr><tr><td><a href="#%28part._tensorflow_leaky-relu%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">leaky-<wbr></wbr>relu</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-log%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>log</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-log-plus1%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>log-<wbr></wbr>plus1</span></a></td></tr><tr><td><a href="#%28part._tensorflow_log-sigmoid%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">log-<wbr></wbr>sigmoid</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-negate%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>negate</span></a></td></tr><tr><td><a href="#%28part._tensorflow_parametric-relu%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">parametric-<wbr></wbr>relu</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-reciprocal%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>reciprocal</span></a></td></tr><tr><td><a href="#%28part._tensorflow_relu%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">relu</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-round%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>round</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reciprocal-sqrt%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reciprocal-<wbr></wbr>sqrt</span></a></td></tr><tr><td><a href="#%28part._tensorflow_scaled-elu%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">scaled-<wbr></wbr>elu</span></a></td></tr><tr><td><a href="#%28part._tensorflow_sigmoid%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">sigmoid</span></a></td></tr><tr><td><a href="#%28part._tensorflow_signed-ones%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">signed-<wbr></wbr>ones</span></a></td></tr><tr><td><a href="#%28part._tensorflow_softplus%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">softplus</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-sqrt%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>sqrt</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tensor-square%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tensor-<wbr></wbr>square</span></a></td></tr><tr><td><a href="#%28part._tensorflow_step%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">step</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.2.4<tt>&nbsp;</tt></span><a href="#%28part._.Reduction_.Operations%29" class="tocsubseclink" data-pltdoc="x">Reduction Operations</a></td></tr><tr><td><a href="#%28part._tensorflow_arg-max%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">arg-<wbr></wbr>max</span></a></td></tr><tr><td><a href="#%28part._tensorflow_arg-min%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">arg-<wbr></wbr>min</span></a></td></tr><tr><td><a href="#%28part._tensorflow_log-sum-exp%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">log-<wbr></wbr>sum-<wbr></wbr>exp</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-all%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>all</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-any%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>any</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-max%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>max</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-min%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>min</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-mean%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>mean</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reduce-sum%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reduce-<wbr></wbr>sum</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.2.5<tt>&nbsp;</tt></span><a href="#%28part._.Slicing_and_.Joining_.Operations%29" class="tocsubseclink" data-pltdoc="x">Slicing and Joining Operations</a></td></tr><tr><td><a href="#%28part._tensorflow_concatenate%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">concatenate</span></a></td></tr><tr><td><a href="#%28part._tensorflow_gather%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">gather</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reverse%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reverse</span></a></td></tr><tr><td><a href="#%28part._tensorflow_slice%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">slice</span></a></td></tr><tr><td><a href="#%28part._tensorflow_split%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">split</span></a></td></tr><tr><td><a href="#%28part._tensorflow_stack%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">stack</span></a></td></tr><tr><td><a href="#%28part._tensorflow_tile%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">tile</span></a></td></tr><tr><td><a href="#%28part._tensorflow_unstack%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">unstack</span></a></td></tr><tr><td><a href="#%28part._tensorflow_strided-slice%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">strided-<wbr></wbr>slice</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.3<tt>&nbsp;</tt></span><a href="#%28part._.Tensor.Buffers%29" class="tocsubseclink" data-pltdoc="x">Tensor<span class="mywbr"> &nbsp;</span>Buffers</a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Tensor<span class="mywbr"> &nbsp;</span>Buffer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-tensor-buffer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>tensor-<wbr></wbr>buffer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.3.1<tt>&nbsp;</tt></span><a href="#%28part._.Tensor.Buffer_.Constructors%29" class="tocsubseclink" data-pltdoc="x">Tensor<span class="mywbr"> &nbsp;</span>Buffer Constructors</a></td></tr><tr><td><a href="#%28part._tensorflow_make-buffer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>buffer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.3.2<tt>&nbsp;</tt></span><a href="#%28part._.Tensor.Buffer_.Methods%29" class="tocsubseclink" data-pltdoc="x">Tensor<span class="mywbr"> &nbsp;</span>Buffer Methods</a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_size%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.size</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_shape%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.shape</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_set-now%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.set-<wbr></wbr>now</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_get-now%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.get-<wbr></wbr>now</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_get-all-now%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.get-<wbr></wbr>all-<wbr></wbr>now</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Tensor.Buffer_shared._methods_to-tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.to-<wbr></wbr>tensor</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.4<tt>&nbsp;</tt></span><a href="#%28part._.Models%29" class="tocsubseclink" data-pltdoc="x">Models</a></td></tr><tr><td><span class="tocsublinknumber">3.28.4.1<tt>&nbsp;</tt></span><a href="#%28part._.Generic_.Models%29" class="tocsubseclink" data-pltdoc="x">Generic Models</a></td></tr><tr><td><a href="#%28part._tensorflow_.Model%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Model</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-model%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>model</span></a></td></tr><tr><td><a href="#%28part._tensorflow_make-model%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>model</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.4.2<tt>&nbsp;</tt></span><a href="#%28part._.Sequential_.Models%29" class="tocsubseclink" data-pltdoc="x">Sequential Models</a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Sequential</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-sequential%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>sequential</span></a></td></tr><tr><td><a href="#%28part._tensorflow_make-sequential%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>sequential</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_add%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.add</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_compile%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.compile</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_evaluate%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.evaluate</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_predict%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.predict</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_predict-on-batch%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.predict-<wbr></wbr>on-<wbr></wbr>batch</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Sequential_shared._methods_fit%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.fit</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.5<tt>&nbsp;</tt></span><a href="#%28part._.Symbolic.Tensors%29" class="tocsubseclink" data-pltdoc="x">Symbolic<span class="mywbr"> &nbsp;</span>Tensors</a></td></tr><tr><td><a href="#%28part._tensorflow_.Symbolic.Tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Symbolic<span class="mywbr"> &nbsp;</span>Tensor</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-symbolic-tensor%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>symbolic-<wbr></wbr>tensor</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.5.1<tt>&nbsp;</tt></span><a href="#%28part._.Symbolic.Tensor_.Constructors%29" class="tocsubseclink" data-pltdoc="x">Symbolic<span class="mywbr"> &nbsp;</span>Tensor Constructors</a></td></tr><tr><td><a href="#%28part._tensorflow_make-input%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>input</span></a></td></tr><tr><td><a href="#%28part._tensorflow_make-batch-input%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">make-<wbr></wbr>batch-<wbr></wbr>input</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.5.2<tt>&nbsp;</tt></span><a href="#%28part._.Symbolic.Tensor_.Methods%29" class="tocsubseclink" data-pltdoc="x">Symbolic<span class="mywbr"> &nbsp;</span>Tensor Methods</a></td></tr><tr><td><a href="#%28part._tensorflow_.Symbolic.Tensor_shared._methods_shape%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.shape</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6<tt>&nbsp;</tt></span><a href="#%28part._.Layers%29" class="tocsubseclink" data-pltdoc="x">Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_.Layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.1<tt>&nbsp;</tt></span><a href="#%28part._.Layer-.Specific_.Datatypes%29" class="tocsubseclink" data-pltdoc="x">Layer-<wbr></wbr>Specific Datatypes</a></td></tr><tr><td><a href="#%28part._tensorflow_.Layer.Config%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Layer<span class="mywbr"> &nbsp;</span>Config</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Activation%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Activation</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Initializer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Initializer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Constraint%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Constraint</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Regularizer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Regularizer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Data.Format%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Data<span class="mywbr"> &nbsp;</span>Format</span></a></td></tr><tr><td><a href="#%28part._tensorflow_.Padding.Method%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Padding<span class="mywbr"> &nbsp;</span>Method</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.2<tt>&nbsp;</tt></span><a href="#%28part._.Basic_.Layers%29" class="tocsubseclink" data-pltdoc="x">Basic Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_activation-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">activation-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_dense-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">dense-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_dropout-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">dropout-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_embedding-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">embedding-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_flatten-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">flatten-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_repeat-vector-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">repeat-<wbr></wbr>vector-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_reshape-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">reshape-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.3<tt>&nbsp;</tt></span><a href="#%28part._.Convolutional_.Layers%29" class="tocsubseclink" data-pltdoc="x">Convolutional Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_conv-1d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">conv-<wbr></wbr>1d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_conv-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">conv-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_conv-2d-transpose-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">conv-<wbr></wbr>2d-<wbr></wbr>transpose-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_cropping-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">cropping-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_depthwise-conv-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">depthwise-<wbr></wbr>conv-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_separable-conv-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">separable-<wbr></wbr>conv-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_up-sampling-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">up-<wbr></wbr>sampling-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.4<tt>&nbsp;</tt></span><a href="#%28part._.Merge_.Layers%29" class="tocsubseclink" data-pltdoc="x">Merge Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_add-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">add-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_average-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">average-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_concatenate-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">concatenate-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_maximum-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">maximum-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_minimum-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">minimum-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_multiply-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">multiply-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.5<tt>&nbsp;</tt></span><a href="#%28part._.Normalization_.Layers%29" class="tocsubseclink" data-pltdoc="x">Normalization Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_batch-normalization-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">batch-<wbr></wbr>normalization-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.6<tt>&nbsp;</tt></span><a href="#%28part._.Pooling_.Layers%29" class="tocsubseclink" data-pltdoc="x">Pooling Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_average-pooling-1d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">average-<wbr></wbr>pooling-<wbr></wbr>1d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_average-pooling-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">average-<wbr></wbr>pooling-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_global-average-pooling-1d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">global-<wbr></wbr>average-<wbr></wbr>pooling-<wbr></wbr>1d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_global-average-pooling-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">global-<wbr></wbr>average-<wbr></wbr>pooling-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_global-max-pooling-1d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">global-<wbr></wbr>max-<wbr></wbr>pooling-<wbr></wbr>1d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_global-max-pooling-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">global-<wbr></wbr>max-<wbr></wbr>pooling-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_max-pooling-1d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">max-<wbr></wbr>pooling-<wbr></wbr>1d-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_max-pooling-2d-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">max-<wbr></wbr>pooling-<wbr></wbr>2d-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.7<tt>&nbsp;</tt></span><a href="#%28part._.Recurrent_.Layers%29" class="tocsubseclink" data-pltdoc="x">Recurrent Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_gru-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">gru-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_gru-cell-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">gru-<wbr></wbr>cell-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_lstm-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">lstm-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_lstm-cell-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">lstm-<wbr></wbr>cell-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_rnn-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">rnn-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_simple-rnn-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">simple-<wbr></wbr>rnn-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_simple-rnn-cell-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">simple-<wbr></wbr>rnn-<wbr></wbr>cell-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_stacked-rnn-cells-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">stacked-<wbr></wbr>rnn-<wbr></wbr>cells-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.6.8<tt>&nbsp;</tt></span><a href="#%28part._.Wrapper_.Layers%29" class="tocsubseclink" data-pltdoc="x">Wrapper Layers</a></td></tr><tr><td><a href="#%28part._tensorflow_bidirectional-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">bidirectional-<wbr></wbr>layer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_time-distributed-layer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">time-<wbr></wbr>distributed-<wbr></wbr>layer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.7<tt>&nbsp;</tt></span><a href="#%28part._.Optimizers%29" class="tocsubseclink" data-pltdoc="x">Optimizers</a></td></tr><tr><td><a href="#%28part._tensorflow_.Optimizer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">Optimizer</span></a></td></tr><tr><td><a href="#%28part._tensorflow_is-optimizer%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">is-<wbr></wbr>optimizer</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.7.1<tt>&nbsp;</tt></span><a href="#%28part._.Optimizer_.Constructors%29" class="tocsubseclink" data-pltdoc="x">Optimizer Constructors</a></td></tr><tr><td><a href="#%28part._tensorflow_train-sgd%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>sgd</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-momentum%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>momentum</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-adagrad%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>adagrad</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-adadelta%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>adadelta</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-adam%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>adam</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-adamax%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>adamax</span></a></td></tr><tr><td><a href="#%28part._tensorflow_train-rmsprop%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">train-<wbr></wbr>rmsprop</span></a></td></tr><tr><td><span class="tocsublinknumber">3.28.7.2<tt>&nbsp;</tt></span><a href="#%28part._.Optimizer_.Methods%29" class="tocsubseclink" data-pltdoc="x">Optimizer Methods</a></td></tr><tr><td><a href="#%28part._tensorflow_.Optimizer_shared._methods_minimize%29" class="tocsubnonseclink" data-pltdoc="x"><span class="stt">.minimize</span></a></td></tr></table></div></div><div class="maincolumn"><div class="main"><div class="versionbox"><span class="version">6.12</span></div><div class="navsettop"><span class="navleft"><form class="searchform"><input class="searchbox" style="color: #888;" type="text" value="...search manuals..." title="Enter a search string to search the manuals" onkeypress="return DoSearchKey(event, this, &quot;6.12&quot;, &quot;&quot;);" onfocus="this.style.color=&quot;black&quot;; this.style.textAlign=&quot;left&quot;; if (this.value == &quot;...search manuals...&quot;) this.value=&quot;&quot;;" onblur="if (this.value.match(/^ *$/)) { this.style.color=&quot;#888&quot;; this.style.textAlign=&quot;center&quot;; this.value=&quot;...search manuals...&quot;; }"/></form>&nbsp;&nbsp;</span><span class="navright">&nbsp;&nbsp;<a href="math.html" title="backward to &quot;3.27 math&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="Builtins_and_Libraries.html" title="up to &quot;3 Builtins and Libraries&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Pyret_Style_Guide.html" title="forward to &quot;4 Pyret Style Guide&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div><h4>3.28<tt>&nbsp;</tt><a name="(part._tensorflow)"></a>tensorflow</h4><p><div class="SIntrapara">Usage:</div><div class="SIntrapara"><span class="pyret-highlight"><span class="stt">include tensorflow</span></span></div><div class="SIntrapara"><span class="pyret-highlight"><span class="stt">import tensorflow as ...</span></span></div><div class="SIntrapara">A module that provides a Pyret interface for TensorFlow, a
symbolic math library for machine learning applications.</div></p><table cellspacing="0" cellpadding="0"><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensors%29" class="toclink" data-pltdoc="x">3.28.1<span class="hspace">&nbsp;</span>Tensors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor_.Constructors%29" class="toclink" data-pltdoc="x">3.28.1.1<span class="hspace">&nbsp;</span>Tensor Constructors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor_.Methods%29" class="toclink" data-pltdoc="x">3.28.1.2<span class="hspace">&nbsp;</span>Tensor Methods</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor_.Operations%29" class="toclink" data-pltdoc="x">3.28.2<span class="hspace">&nbsp;</span>Tensor Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Arithmetic_.Operations%29" class="toclink" data-pltdoc="x">3.28.2.1<span class="hspace">&nbsp;</span>Arithmetic Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Trigonometry_.Operations%29" class="toclink" data-pltdoc="x">3.28.2.2<span class="hspace">&nbsp;</span>Trigonometry Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Math_.Operations%29" class="toclink" data-pltdoc="x">3.28.2.3<span class="hspace">&nbsp;</span>Math Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Reduction_.Operations%29" class="toclink" data-pltdoc="x">3.28.2.4<span class="hspace">&nbsp;</span>Reduction Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Slicing_and_.Joining_.Operations%29" class="toclink" data-pltdoc="x">3.28.2.5<span class="hspace">&nbsp;</span>Slicing and Joining Operations</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor.Buffers%29" class="toclink" data-pltdoc="x">3.28.3<span class="hspace">&nbsp;</span>TensorBuffers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor.Buffer_.Constructors%29" class="toclink" data-pltdoc="x">3.28.3.1<span class="hspace">&nbsp;</span>TensorBuffer Constructors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Tensor.Buffer_.Methods%29" class="toclink" data-pltdoc="x">3.28.3.2<span class="hspace">&nbsp;</span>TensorBuffer Methods</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Models%29" class="toclink" data-pltdoc="x">3.28.4<span class="hspace">&nbsp;</span>Models</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Generic_.Models%29" class="toclink" data-pltdoc="x">3.28.4.1<span class="hspace">&nbsp;</span>Generic Models</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Sequential_.Models%29" class="toclink" data-pltdoc="x">3.28.4.2<span class="hspace">&nbsp;</span>Sequential Models</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Symbolic.Tensors%29" class="toclink" data-pltdoc="x">3.28.5<span class="hspace">&nbsp;</span>SymbolicTensors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Symbolic.Tensor_.Constructors%29" class="toclink" data-pltdoc="x">3.28.5.1<span class="hspace">&nbsp;</span>SymbolicTensor Constructors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Symbolic.Tensor_.Methods%29" class="toclink" data-pltdoc="x">3.28.5.2<span class="hspace">&nbsp;</span>SymbolicTensor Methods</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Layers%29" class="toclink" data-pltdoc="x">3.28.6<span class="hspace">&nbsp;</span>Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Layer-.Specific_.Datatypes%29" class="toclink" data-pltdoc="x">3.28.6.1<span class="hspace">&nbsp;</span>Layer-Specific Datatypes</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Basic_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.2<span class="hspace">&nbsp;</span>Basic Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Convolutional_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.3<span class="hspace">&nbsp;</span>Convolutional Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Merge_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.4<span class="hspace">&nbsp;</span>Merge Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Normalization_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.5<span class="hspace">&nbsp;</span>Normalization Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Pooling_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.6<span class="hspace">&nbsp;</span>Pooling Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Recurrent_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.7<span class="hspace">&nbsp;</span>Recurrent Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Wrapper_.Layers%29" class="toclink" data-pltdoc="x">3.28.6.8<span class="hspace">&nbsp;</span>Wrapper Layers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Optimizers%29" class="toclink" data-pltdoc="x">3.28.7<span class="hspace">&nbsp;</span>Optimizers</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Optimizer_.Constructors%29" class="toclink" data-pltdoc="x">3.28.7.1<span class="hspace">&nbsp;</span>Optimizer Constructors</a></p></td></tr><tr><td><p><span class="hspace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="#%28part._.Optimizer_.Methods%29" class="toclink" data-pltdoc="x">3.28.7.2<span class="hspace">&nbsp;</span>Optimizer Methods</a></p></td></tr></table><h5>3.28.1<tt>&nbsp;</tt><a name="(part._.Tensors)"></a>Tensors</h5><p><div class="SIntrapara"><a name="(idx._(gentag._579))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">Tensor</span>s are the core datastructure for <span class="pyret-highlight"><span class="stt">tensorflow</span></span>
applications. They are a generalization of vectors and matrices that
allows for higher dimensions.</div></p><p>For example, a tensor could be a one-dimensional matrix (a vector), a
three-dimensional matrix (a cube), a zero-dimensional matrix (a single
number), or a higher dimensional structure that is more difficult to
visualize.</p><blockquote class="refpara"><blockquote class="refcolumn"><blockquote class="refcontent"><p>This is because TensorFlow.js (the library that the <span class="stt">tensorflow</span>
library is built on) stores <span class="stt">Tensor</span> values in JavaScript
<span class="stt">Float32Array</span>s for performance reasons.</p></blockquote></blockquote></blockquote><p>For performance reasons, <span class="stt">Tensor</span>s do not support arbitrary
precision. Retrieving values from a <span class="stt">Tensor</span> using
<a href="#%28part._tensorflow_.Tensor_shared._methods_data-now%29" data-pltdoc="x"><span class="stt">.data-now</span></a> always returns a
<span class="pyret-highlight"><span class="stt">List&lt;Roughnum&gt;</span></span>.</p><p>Since <span class="stt">Tensor</span>s are immutable, all operations always return new
<span class="stt">Tensor</span>s and never modify the input <span class="stt">Tensor</span>s. The exception
to this is when a <span class="stt">Tensor</span> is transformed into a mutable
<span class="stt">Tensor</span> using the <a href="#%28part._tensorflow_make-variable%29" data-pltdoc="x"><span class="stt">make-variable</span></a> function or the
<a href="#%28part._tensorflow_.Tensor_shared._methods_to-variable%29" data-pltdoc="x"><span class="stt">.to-variable</span></a> method. These "variable tensors"
can be modified by <span class="stt">Optimizer</span>s.</p><h5>3.28.1.1<tt>&nbsp;</tt><a name="(part._.Tensor_.Constructors)"></a>Tensor Constructors</h5><div class="boxed pyret-header"><span class="stt">[</span><a name="(part._tensorflow_tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor%29" data-pltdoc="x"><span class="stt">tensor</span></a><span class="stt">: </span><span class="stt">value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">, ...</span><span class="stt">] -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><p>Creates a new <span class="stt">Tensor</span> with the given <span class="pyret-highlight"><span class="stt">value</span></span>s.</p><p>Every <span class="stt">Tensor</span> created with this constructor is one-dimensional. Use
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-1d%29" data-pltdoc="x"><span class="stt">.as-1d</span></a>, <a href="#%28part._tensorflow_.Tensor_shared._methods_as-2d%29" data-pltdoc="x"><span class="stt">.as-2d</span></a>,
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-3d%29" data-pltdoc="x"><span class="stt">.as-3d</span></a>, <a href="#%28part._tensorflow_.Tensor_shared._methods_as-4d%29" data-pltdoc="x"><span class="stt">.as-4d</span></a>, or
<a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a> to change the shape of a <span class="stt">Tensor</span>
after instantiating it.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>[tensor: 1, 2, 3] # a size-3 tensor
[tensor: 1.4, 5.2, 0.4, 12.4, 14.3, 6].as-2d(3, 2) # a 3 x 2 tensor
[tensor: 9, 4, 0, -32, 23, 1, 3, 2].as-3d(2, 2, 2) # a 2 x 2 x 2 tensor</p></pre></pre></div></p></div><p><a name="(idx._(gentag._580))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_is-tensor%29" data-pltdoc="x"><span class="stt">is-tensor</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">Tensor</span>; otherwise, returns
<span class="pyret-highlight"><span class="stt">false</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  is-tensor([tensor: 1, 2, 3]) is true
  is-tensor(true) is false
  is-tensor(0) is false
  is-tensor([list: 1, 2, 3]) is false
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._581))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_list-to-tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_list-to-tensor%29" data-pltdoc="x"><span class="stt">list-to-tensor</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">values</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Tensor</span> with the values in the input <span class="pyret-highlight"><span class="stt">List</span></span>.</p><p>Similar to the <a href="#%28part._tensorflow_tensor%29" data-pltdoc="x"><span class="stt">tensor</span></a> constructor, all <span class="stt">Tensor</span>s created
using <a href="#%28part._tensorflow_list-to-tensor%29" data-pltdoc="x"><span class="stt">list-to-tensor</span></a> are one-dimensional by default. Use
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-1d%29" data-pltdoc="x"><span class="stt">.as-1d</span></a>, <a href="#%28part._tensorflow_.Tensor_shared._methods_as-2d%29" data-pltdoc="x"><span class="stt">.as-2d</span></a>,
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-3d%29" data-pltdoc="x"><span class="stt">.as-3d</span></a>, <a href="#%28part._tensorflow_.Tensor_shared._methods_as-4d%29" data-pltdoc="x"><span class="stt">.as-4d</span></a>, or
<a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a> to change the shape of a <span class="stt">Tensor</span>
after instantiating it.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  list-to-tensor(empty) satisfies is-tensor
  list-to-tensor([list: 5, 3, 4, 7]) satisfies is-tensor

  list-to-tensor(empty).data-now() is empty
  list-to-tensor([list: 9, 3, 2, 3]).data-now() is-roughly [list: 9, 3, 2, 3]
  list-to-tensor([list: 3, 2, 1, 0, 4, 9]).as-2d(2, 3).shape() is [list: 2, 3]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._582))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-scalar)" class="pyret-code"></a><a href="#%28part._tensorflow_make-scalar%29" data-pltdoc="x"><span class="stt">make-scalar</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Tensor</span> of rank-0 with the given <span class="pyret-highlight"><span class="stt">value</span></span>.</p><p>The same functionality can be achieved with the <a href="#%28part._tensorflow_tensor%29" data-pltdoc="x"><span class="stt">tensor</span></a>
constructor and the <a href="#%28part._tensorflow_.Tensor_shared._methods_as-scalar%29" data-pltdoc="x"><span class="stt">.as-scalar</span></a> method, but it&rsquo;s
recommended to use <a href="#%28part._tensorflow_make-scalar%29" data-pltdoc="x"><span class="stt">make-scalar</span></a> as it makes the code more
readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-scalar(1).size() is 1
  make-scalar(~12.3).shape() is empty
  make-scalar(2.34).data-now() is-roughly [list: 2.34]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._583))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_fill)" class="pyret-code"></a><a href="#%28part._tensorflow_fill%29" data-pltdoc="x"><span class="stt">fill</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span>, <span class="stt">value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a <span class="stt">Tensor</span> with the input <span class="pyret-highlight"><span class="stt">shape</span></span> where all of the
entries are <span class="pyret-highlight"><span class="stt">value</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  fill([list: 0], 1).data-now()
    is-roughly [list: ]
  fill([list: 3], 5).data-now()
    is-roughly [list: 5, 5, 5]
  fill([list: 3, 2], -3).data-now()
    is-roughly [list: -3, -3, -3, -3, -3, -3]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._584))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_linspace)" class="pyret-code"></a><a href="#%28part._tensorflow_linspace%29" data-pltdoc="x"><span class="stt">linspace</span></a> :: (</dt><dt class="indent-arg"><span class="stt">start</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">stop</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">num-values</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="stt">Tensor</span> whose values are an evenly spaced sequence of
numbers over the range <span class="pyret-highlight"><span class="stt">[start, stop]</span></span>. <span class="pyret-highlight"><span class="stt">num-values</span></span> is the
number of entries in the output <span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  linspace(0, 3, 1).data-now()
    is-roughly [list: 0]
  linspace(10, 11, 1).data-now()
    is-roughly [list: 10]
  linspace(5, 1, 5).data-now()
    is-roughly [list: 5, 4, 3, 2, 1]
  linspace(0, 9, 10).data-now()
    is-roughly [list: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
  linspace(0, 4, 9).data-now()
    is-roughly [list: 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._585))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_ones)" class="pyret-code"></a><a href="#%28part._tensorflow_ones%29" data-pltdoc="x"><span class="stt">ones</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="stt">Tensor</span> with the given <span class="pyret-highlight"><span class="stt">shape</span></span> where all of the
entries are ones.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  ones([list: 0]).data-now() is-roughly [list: ]
  ones([list: 4]).data-now() is-roughly [list: 1, 1, 1, 1]
  two-dim = ones([list: 3, 2])
  two-dim.shape() is [list: 3, 2]
  two-dim.data-now() is-roughly [list: 1, 1, 1, 1, 1, 1]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._586))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_zeros)" class="pyret-code"></a><a href="#%28part._tensorflow_zeros%29" data-pltdoc="x"><span class="stt">zeros</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="stt">Tensor</span> with the given <span class="pyret-highlight"><span class="stt">shape</span></span> where all of the
entries are zeros.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  zeros([list: 0]).data-now() is-roughly [list: ]
  zeros([list: 4]).data-now() is-roughly [list: 0, 0, 0, 0]
  two-dim = zeros([list: 3, 2])
  two-dim.shape() is [list: 3, 2]
  two-dim.data-now() is-roughly [list: 0, 0, 0, 0, 0, 0]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._587))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_multinomial)" class="pyret-code"></a><a href="#%28part._tensorflow_multinomial%29" data-pltdoc="x"><span class="stt">multinomial</span></a> :: (</dt><dt class="indent-arg"><span class="stt">logits</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">num-samples</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Positive%29" data-pltdoc="x"><span class="stt">NumPositive</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">seed</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">is-normalized</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Tensor</span> where all of the values are sampled from a
multinomial distribution.</p><p><span class="pyret-highlight"><span class="stt">logits</span></span> should be a <span class="stt">Tensor</span> representing a one-dimensional
array containing with unnormalized log-probabilities, or a two-dimensional
array of structure <span class="pyret-highlight"><span class="stt">[batch-size, num-outcomes]</span></span>.</p><p><span class="pyret-highlight"><span class="stt">num-samples</span></span> is the number of samples to draw for each row slice.
<span class="pyret-highlight"><span class="stt">seed</span></span> represents the random seed to use when generating values; if
<span class="pyret-highlight"><span class="stt">none</span></span>, the seed is randomly generated. <span class="pyret-highlight"><span class="stt">normalized</span></span> designates
whether or not the provided logits are normalized true probabilities (i.e:
they sum to 1).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  three-dim = [tensor: 1, 1, 1, 1, 1, 1, 1, 1].as-3d(2, 2, 2)
  multinomial(three-dim, 2, none, false)
    raises "must be a one-dimensional or two-dimensional Tensor"

  multinomial([tensor: ], 1, none, false)
    raises "must have at least two possible outcomes"
  multinomial([tensor: 0.8], 7, none, false)
    raises "must have at least two possible outcomes"

  multinomial([tensor: 1.0, 0.0], 1, none, true).shape() is [list: 1]
  multinomial([tensor: 1.0, 0.0], 3, none, true).shape() is [list: 3]
  multinomial([tensor: 0.3, 0.5, 0.7], 10, none, false).shape() is [list: 10]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._588))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_random-normal)" class="pyret-code"></a><a href="#%28part._tensorflow_random-normal%29" data-pltdoc="x"><span class="stt">random-normal</span></a> :: (</dt><dt class="indent-arg"><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">mean</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">standard-deviation</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Tensor</span> with the given shape (represented as values in
the input <span class="pyret-highlight"><span class="stt">List&lt;Number&gt; shape</span></span>) where all of the values are sampled
from a normal distribution.</p><p><span class="pyret-highlight"><span class="stt">mean</span></span> is the mean of the normal distribution and
<span class="pyret-highlight"><span class="stt">standard-deviation</span></span> is the standard deviation of the normal
distribution. If <span class="pyret-highlight"><span class="stt">none</span></span>, the respective parameters are set to the
TensorFlow.js defaults.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  random-normal(empty, none, none).size() is 1
  random-normal(empty, none, none).shape() is empty
  random-normal([list: 4, 3], none, none).shape() is [list: 4, 3]
  random-normal([list: 2, 5, 3], none, none).shape() is [list: 2, 5, 3]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._589))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_random-uniform)" class="pyret-code"></a><a href="#%28part._tensorflow_random-uniform%29" data-pltdoc="x"><span class="stt">random-uniform</span></a> :: (</dt><dt class="indent-arg"><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">min-val</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">max-val</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Tensor</span> with the given shape (represented as values in
the input <span class="pyret-highlight"><span class="stt">List</span></span>) where all of the values are sampled from a uniform
distribution.</p><p><span class="pyret-highlight"><span class="stt">min-val</span></span> is the lower bound on the range of random values to generate
and <span class="pyret-highlight"><span class="stt">max-val</span></span> is the upper bound on the range of random values to
generate. If <span class="pyret-highlight"><span class="stt">none</span></span>, the respective parameters are set to the
TensorFlow.js defaults.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  random-uniform(empty, none, none).size() is 1
  random-uniform(empty, none, none).shape() is empty
  random-uniform([list: 1, 3], none, none).shape() is [list: 1, 3]
  random-uniform([list: 5, 4, 8], none, none).shape() is [list: 5, 4, 8]

  lower-bound = 1
  upper-bound = 10
  random-data = random-uniform([list: 20], some(lower-bound), some(upper-bound))
  for each(data-point from random-data.data-now()):
    data-point satisfies lam(x): (x &gt;= lower-bound) and (x &lt;= upper-bound) end
  end
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._590))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-variable)" class="pyret-code"></a><a href="#%28part._tensorflow_make-variable%29" data-pltdoc="x"><span class="stt">make-variable</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">initial-value</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new, mutable <span class="stt">Tensor</span> initialized to the values of the input
<span class="stt">Tensor</span>.</p><p>The same functionality can be achieved with the
<a href="#%28part._tensorflow_.Tensor_shared._methods_to-variable%29" data-pltdoc="x"><span class="stt">.to-variable</span></a> method.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-variable([tensor: ]).data-now() is-roughly empty
  make-variable([tensor: 1]).data-now() is-roughly [list: 1]

  # We can perform normal Tensor operations on mutable Tensors:
  two-dim = [tensor: 4, 5, 3, 9].as-2d(2, 2)
  make-variable(two-dim).size() is 4
  make-variable(two-dim).shape() is [list: 2, 2]
  make-variable(two-dim).data-now() is-roughly [list: 4, 5, 3, 9]
  make-variable(two-dim).as-3d(4, 1, 1).shape() is [list: 4, 1, 1]
end</p></pre></pre></div></p></div><h5>3.28.1.2<tt>&nbsp;</tt><a name="(part._.Tensor_.Methods)"></a>Tensor Methods</h5><p><a name="(idx._(gentag._591))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_size)" class="pyret-code"></a><span class="stt">.size</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns the size of the <span class="stt">Tensor</span> (the number of values stored in the
<span class="stt">Tensor</span>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-scalar(4.21).size() is 1
  [tensor: 6.32].size() is 1
  [tensor: 1, 2, 3].size() is 3
  [tensor: 1.4, 5.2, 0.4, 12.4, 14.3, 6].as-2d(3, 2).size() is 6
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._592))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_shape)" class="pyret-code"></a><span class="stt">.shape</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="pyret-highlight"><span class="stt">List&lt;NumInteger&gt;</span></span> representing the shape of the
<span class="stt">Tensor</span>. Each element in the <span class="pyret-highlight"><span class="stt">List&lt;NumInteger&gt;</span></span> corresponds
to the size in each dimension.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-scalar(3).shape() is empty
  [tensor: 9].shape() is [list: 1]
  [tensor: 8, 3, 1].shape() is [list: 3]
  [tensor: 0, 0, 0, 0, 0, 0].as-2d(3, 2).shape() is [list: 3, 2]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._593))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_flatten)" class="pyret-code"></a><span class="stt">.flatten</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, one-dimensional <span class="stt">Tensor</span> from the values of the
original <span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  a = [tensor: 1, 2, 3, 4, 5, 6].as-2d(3, 2)
  a.shape() is [list: 3, 2]
  a.flatten().shape() is [list: 6]

  b = make-scalar(12)
  b.shape() is empty
  b.flatten().shape() is [list: 1]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._594))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_as-scalar)" class="pyret-code"></a><span class="stt">.as-scalar</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, zero-dimensional <span class="stt">Tensor</span> from the values of the
original, size-1 <span class="stt">Tensor</span>.</p><p>Raises an error if the calling <span class="stt">Tensor</span> is not size-1.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  size-one = [tensor: 1]
  size-one.as-scalar().shape() is empty
  size-one.shape() is [list: 1] # doesn't modify shape of original tensor

  size-two = [tensor: 1, 2]
  size-two.as-scalar() raises
    "Tensor was size-2 but `as-scalar` requires the tensor to be size-1"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._595))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_as-1d)" class="pyret-code"></a><span class="stt">.as-1d</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, rank-1 <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span>.</p><p>The same functionality can be achieved with <a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a>,
but it&rsquo;s recommended to use <a href="#%28part._tensorflow_.Tensor_shared._methods_as-1d%29" data-pltdoc="x"><span class="stt">.as-1d</span></a> as it makes the
code more readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = [tensor: 1]
  two-dim = [tensor: 4, 3, 2, 1].as-2d(2, 2)
  three-dim = [tensor: 0, 1, 2, 3, 4, 5, 6, 7, 8].as-3d(3, 1, 3)

  one-dim.shape() is [list: 1]
  one-dim.as-1d().shape() is [list: 1]

  two-dim.shape() is [list: 2, 2]
  two-dim.as-1d().shape() is [list: 4]

  three-dim.shape() is [list: 3, 1, 3]
  three-dim.as-1d().shape() is [list: 9]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._596))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_as-2d)" class="pyret-code"></a><span class="stt">.as-2d</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">rows</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>, <span class="stt">columns</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, rank-2 <span class="stt">Tensor</span> with the input dimensions from the
values of the original <span class="stt">Tensor</span>.</p><p>The number of elements implied by the input dimensions must be the same as the
number of elements in the calling <span class="stt">Tensor</span>. Otherwise, the method
raises an error.</p><p>The same functionality can be achieved with <a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a>,
but it&rsquo;s recommended to use <a href="#%28part._tensorflow_.Tensor_shared._methods_as-2d%29" data-pltdoc="x"><span class="stt">.as-2d</span></a> as it makes the
code more readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = [tensor: 1]
  two-dim = [tensor: 0, 1, 2, 3, 4, 5].as-2d(3, 2)
  three-dim = [tensor: 4, 3, 2, 1, 0, -1, -2, -3].as-3d(2, 2, 2)

  one-dim.shape() is [list: 1]
  one-dim.as-2d(1, 1).shape() is [list: 1, 1]

  two-dim.shape() is [list: 3, 2]
  two-dim.as-2d(2, 3).shape() is [list: 2, 3]

  three-dim.shape() is [list: 2, 2, 2]
  three-dim.as-2d(4, 2).shape() is [list: 4, 2]

  one-dim.as-2d(2, 1) raises "Cannot reshape"
  two-dim.as-2d(3, 3) raises "Cannot reshape"
  three-dim.as-2d(5, 4) raises "Cannot reshape"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._597))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_.Tensor_shared._methods_as-3d)" class="pyret-code"></a><span class="stt">.as-3d</span> :: (</dt><dt class="indent-arg"><span class="stt">rows</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">columns</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">depth</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, rank-3 <span class="stt">Tensor</span> with the input dimensions from the
values of the original <span class="stt">Tensor</span>.</p><p>The number of elements implied by the input dimensions must be the same as the
number of elements in the calling <span class="stt">Tensor</span>. Otherwise, the method
raises an error.</p><p>The same functionality can be achieved with <a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a>,
but it&rsquo;s recommended to use <a href="#%28part._tensorflow_.Tensor_shared._methods_as-3d%29" data-pltdoc="x"><span class="stt">.as-3d</span></a> as it makes the
code more readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = [tensor: 1]
  two-dim = [tensor: 0, 1, 2, 3, 4, 5, 6, 7].as-2d(4, 2)

  one-dim.shape() is [list: 1]
  one-dim.as-3d(1, 1, 1).shape() is [list: 1, 1, 1]

  two-dim.shape() is [list: 4, 2]
  two-dim.as-3d(2, 2, 2).shape() is [list: 2, 2, 2]

  one-dim.as-3d(2, 1, 1) raises "Cannot reshape"
  two-dim.as-3d(4, 3, 2) raises "Cannot reshape"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._598))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_.Tensor_shared._methods_as-4d)" class="pyret-code"></a><span class="stt">.as-4d</span> :: (</dt><dt class="indent-arg"><span class="stt">rows</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">columns</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">depth1</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">depth2</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, rank-4 <span class="stt">Tensor</span> with the input dimensions from the
values of the original <span class="stt">Tensor</span>.</p><p>The number of elements implied by the input dimensions must be the same as the
number of elements in the calling <span class="stt">Tensor</span>. Otherwise, the method
raises an error.</p><p>The same functionality can be achieved with <a href="#%28part._tensorflow_.Tensor_shared._methods_reshape%29" data-pltdoc="x"><span class="stt">.reshape</span></a>,
but it&rsquo;s recommended to use <a href="#%28part._tensorflow_.Tensor_shared._methods_as-4d%29" data-pltdoc="x"><span class="stt">.as-4d</span></a> as it makes the
code more readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = [tensor: 1]
  two-dim = [tensor: 0, 1, 2, 3, 4, 5, 6, 7].as-2d(4, 2)

  one-dim.shape() is [list: 1]
  one-dim.as-4d(1, 1, 1, 1).shape() is [list: 1, 1, 1, 1]

  two-dim.shape() is [list: 4, 2]
  two-dim.as-4d(2, 2, 1, 2).shape() is [list: 2, 2, 1, 2]

  one-dim.as-4d(2, 1, 1, 1) raises "Cannot reshape"
  two-dim.as-4d(2, 2, 2, 2) raises "Cannot reshape"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._599))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_as-type)" class="pyret-code"></a><span class="stt">.as-type</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">data-type</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span> with all of the values cast to the input datatype.</p><p>The possible <span class="pyret-highlight"><span class="stt">data-type</span></span>s are <span class="pyret-highlight"><span class="stt">"float32"</span></span>, <span class="pyret-highlight"><span class="stt">"int32"</span></span>, or
<span class="pyret-highlight"><span class="stt">"bool"</span></span>. Any other <span class="pyret-highlight"><span class="stt">data-type</span></span> will raise an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  some-tensor = [tensor: 1, 3, 5, 8]

  some-tensor.as-type("float32") does-not-raise
  some-tensor.as-type("int32") does-not-raise
  some-tensor.as-type("bool") does-not-raise
  some-tensor.as-type("invalid")
    raises "Attempted to cast tensor to invalid type"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._600))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_data-now)" class="pyret-code"></a><span class="stt">.data-now</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Roughnum%29" data-pltdoc="x"><span class="stt">Roughnum</span></a><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="pyret-highlight"><span class="stt">List</span></span> containing the data in the <span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: ].data-now() is-roughly [list: ]
  [tensor: 1].data-now() is-roughly [list: 1]
  [tensor: 1.43].data-now() is-roughly [list: 1.43]
  [tensor: -3.21, 9.4, 0.32].data-now() is-roughly [list: -3.21, 9.4, 0.32]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._601))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_to-float)" class="pyret-code"></a><span class="stt">.to-float</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span> with all of the values cast to the <span class="stt">"float32"</span> datatype.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].to-float().data-now() is-roughly [list: 0]
  [tensor: 1].to-float().data-now() is-roughly [list: 1]
  [tensor: 0.42].to-float().data-now() is-roughly [list: 0.42]
  [tensor: 4, 0.32, 9.40, 8].to-float().data-now()
    is-roughly [list: 4, 0.32, 9.40, 8]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._602))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_to-int)" class="pyret-code"></a><span class="stt">.to-int</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span> with all of the values cast to the <span class="stt">"int32"</span> datatype.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].to-int().data-now() is-roughly [list: 0]
  [tensor: 1].to-int().data-now() is-roughly [list: 1]
  [tensor: 0.999999].to-int().data-now() is-roughly [list: 0]
  [tensor: 1.52, 4.12, 5.99].to-int().data-now()
    is-roughly [list: 1, 4, 5]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._603))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_to-bool)" class="pyret-code"></a><span class="stt">.to-bool</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span> with all of the values cast to the <span class="stt">"bool"</span> datatype.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].to-bool().data-now() is-roughly [list: 0]
  [tensor: 1].to-bool().data-now() is-roughly [list: 1]
  [tensor: 0.42].tox-bool().data-now() is-roughly [list: 1]
  [tensor: 1, 4, 5].to-bool().data-now() is-roughly [list: 1, 1, 1]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._604))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_to-buffer)" class="pyret-code"></a><span class="stt">.to-buffer</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor.Buffer%29" data-pltdoc="x"><span class="stt">TensorBuffer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <a href="#%28part._tensorflow_.Tensor.Buffer%29" data-pltdoc="x"><span class="stt">TensorBuffer</span></a> from the values of the original
<span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  empty-buffer = [tensor: ].to-buffer()
  empty-buffer satisfies is-tensor-buffer
  empty-buffer.get-all-now() is-roughly [list: ]

  some-shape  = [list: 2, 2]
  some-values = [list: 4, 5, 9, 3]
  some-tensor = list-to-tensor(some-values).reshape(some-shape)
  some-buffer = some-tensor.to-buffer()
  some-buffer satisfies is-tensor-buffer
  some-buffer.get-all-now() is-roughly some-values
  some-buffer.to-tensor().shape() is some-shape
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._605))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_to-variable)" class="pyret-code"></a><span class="stt">.to-variable</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new, mutable <span class="stt">Tensor</span> from the values of the original
<span class="stt">Tensor</span>. Equivalent to applying <a href="#%28part._tensorflow_make-variable%29" data-pltdoc="x"><span class="stt">make-variable</span></a> on the
calling <span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: ].to-variable() does-not-raise
  [tensor: 4, 5, 1].to-variable() does-not-raise
  [tensor: 0, 5, 1, 9, 8, 4].as-2d(3, 2).to-variable() does-not-raise
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._606))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_reshape)" class="pyret-code"></a><span class="stt">.reshape</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">new-shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> with the input dimensions <span class="pyret-highlight"><span class="stt">new-shape</span></span>
from the values of the original <span class="stt">Tensor</span>.</p><p>The number of elements implied by <span class="pyret-highlight"><span class="stt">new-shape</span></span> must be the same as the
number of elements in the calling <span class="stt">Tensor</span>. Otherwise, the method
raises an error.</p><p>When reshaping a <span class="stt">Tensor</span> to be 0-, 1-, 2-, 3-, or 4-dimensional,
it&rsquo;s recommended to use <a href="#%28part._tensorflow_.Tensor_shared._methods_as-scalar%29" data-pltdoc="x"><span class="stt">.as-scalar</span></a>,
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-1d%29" data-pltdoc="x"><span class="stt">.as-1d</span></a>, <a href="#%28part._tensorflow_.Tensor_shared._methods_as-2d%29" data-pltdoc="x"><span class="stt">.as-2d</span></a>,
<a href="#%28part._tensorflow_.Tensor_shared._methods_as-3d%29" data-pltdoc="x"><span class="stt">.as-3d</span></a>, or <a href="#%28part._tensorflow_.Tensor_shared._methods_as-4d%29" data-pltdoc="x"><span class="stt">.as-4d</span></a> as
they make the code more readable.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: ].reshape([list: ]) raises "Cannot reshape"
  [tensor: 3, 2].reshape([list: ]) raises "Cannot reshape"
  [tensor: 3, 2].reshape([list: 6]) raises "Cannot reshape"
  [tensor: 3, 2, 1].reshape([list: 2, 4]) raises "Cannot reshape"

  [tensor: 1].reshape([list: 1]).shape() is [list: 1]
  [tensor: 1].reshape([list: 1, 1, 1]).shape() is [list: 1, 1, 1]
  [tensor: 1].reshape([list: 1, 1, 1, 1, 1]).shape() is [list: 1, 1, 1, 1, 1]
  [tensor: 1, 4].reshape([list: 2, 1]).shape() is [list: 2, 1]
  [tensor: 1, 4, 4, 5, 9, 3].reshape([list: 3, 2]).shape() is [list: 3, 2]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._607))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_expand-dims)" class="pyret-code"></a><span class="stt">.expand-dims</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="stt">Tensor</span> that has expanded rank, by inserting a dimension
into the <span class="stt">Tensor</span>&rsquo;s shape at the given dimension index <span class="pyret-highlight"><span class="stt">axis</span></span>.
If <span class="pyret-highlight"><span class="stt">axis</span></span> is <span class="pyret-highlight"><span class="stt">none</span></span>, the method inserts a dimension at index 0
by default.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = [tensor: 1, 2, 3, 4]
  one-dim.shape() is [list: 4]
  one-dim.expand-dims(none).shape() is [list: 1, 4]
  one-dim.expand-dims(some(1)).shape() is [list: 4, 1]

  one-dim.expand-dims(some(2))
    raises "input axis must be less than or equal to the rank of the tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._608))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_squeeze)" class="pyret-code"></a><span class="stt">.squeeze</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">axes</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="stt">Tensor</span> with dimensions of size 1 removed from the shape.</p><p>If <span class="pyret-highlight"><span class="stt">axes</span></span> is not <span class="pyret-highlight"><span class="stt">none</span></span>, the method only squeezes the dimensions
listed as indices in <span class="pyret-highlight"><span class="stt">axes</span></span>. The method will raise an error if one of
the dimensions specified in <span class="pyret-highlight"><span class="stt">axes</span></span> is not of size 1.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  multi-dim = [tensor: 1, 2, 3, 4].reshape([list: 1, 1, 1, 4, 1])
  multi-dim.shape() is [list: 1, 1, 1, 4, 1]
  multi-dim.squeeze(none).shape() is [list: 4]
  multi-dim.squeeze(some([list: 0])).shape() is [list: 1, 1, 4, 1]
  multi-dim.squeeze(some([list: 4])).shape() is [list: 1, 1, 1, 4]
  multi-dim.squeeze(some([list: 1, 2])).shape() is [list: 1, 4, 1]

  multi-dim.squeeze(some([list: 7]))
    raises "Cannot squeeze axis 7 since the axis does not exist"
  multi-dim.squeeze(some([list: 3]))
    raises "Cannot squeeze axis 3 since the dimension of that axis is 4, not 1"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._609))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_clone)" class="pyret-code"></a><span class="stt">.clone</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <span class="stt">Tensor</span> that is a copy of the original <span class="stt">Tensor</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  some-tensor = [tensor: 1, 2, 3, 4]
  new-tensor  = some-tensor.clone()
  new-tensor.size() is some-tensor.size()
  new-tensor.shape() is some-tensor.shape()
  new-tensor.data-now() is-roughly some-tensor.data-now()
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._610))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_add)" class="pyret-code"></a><span class="stt">.add</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Adds <span class="pyret-highlight"><span class="stt">x</span></span> to the <span class="stt">Tensor</span>. This is equivalent to
<a href="#%28part._tensorflow_add-tensors%29" data-pltdoc="x"><span class="stt">add-tensors</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 1].add([tensor: 1]).data-now()
    is-roughly [list: 2]
  [tensor: 1, 3].add([tensor: 1]).data-now()
    is-roughly [list: 2, 4]
  [tensor: 1, 3].add([tensor: 5, 1]).data-now()
    is-roughly [list: 6, 4]
  [tensor: 1, 3, 4].add([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._611))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_subtract)" class="pyret-code"></a><span class="stt">.subtract</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Subtracts <span class="pyret-highlight"><span class="stt">x</span></span> from the <span class="stt">Tensor</span>. This is equivalent to
<a href="#%28part._tensorflow_subtract-tensors%29" data-pltdoc="x"><span class="stt">subtract-tensors</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 1].subtract([tensor: 1]).data-now()
    is-roughly [list: 0]
  [tensor: 1, 3].subtract([tensor: 1]).data-now()
    is-roughly [list: 0, 2]
  [tensor: 1, 3].subtract([tensor: 5, 1]).data-now()
    is-roughly [list: -4, 2]
  [tensor: 1, 3, 4].subtract([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._612))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_multiply)" class="pyret-code"></a><span class="stt">.multiply</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Multiplies the <span class="stt">Tensor</span> by <span class="pyret-highlight"><span class="stt">x</span></span>. This is equivalent to
<a href="#%28part._tensorflow_multiply-tensors%29" data-pltdoc="x"><span class="stt">multiply-tensors</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 1].multiply([tensor: 1]).data-now()
    is-roughly [list: 1]
  [tensor: 1, 3].multiply([tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].multiply([tensor: 5, 1]).data-now()
    is-roughly [list: 5, 3]
  [tensor: 1, 3, 4].multiply([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._613))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_divide)" class="pyret-code"></a><span class="stt">.divide</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Divides the <span class="stt">Tensor</span> by <span class="pyret-highlight"><span class="stt">x</span></span>. This is equivalent to
<a href="#%28part._tensorflow_divide-tensors%29" data-pltdoc="x"><span class="stt">divide-tensors</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 1].divide([tensor: 1]).data-now()
    is-roughly [list: 1]
  [tensor: 1, 3].divide([tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].divide([tensor: 5, 1]).data-now()
    is-roughly [list: 0.2, 3]
  [tensor: 1, 3, 4].divide([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"

  [tensor: 1].divide([tensor: 0])
    raises "The argument Tensor cannot contain 0"
  [tensor: 4.23].divide([tensor: 7.65, 1.43, 0, 2.31])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._614))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_floor-divide)" class="pyret-code"></a><span class="stt">.floor-divide</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Divides the <span class="stt">Tensor</span> by <span class="pyret-highlight"><span class="stt">x</span></span>, with the result rounded
with the floor function. This is equivalent to
<a href="#%28part._tensorflow_floor-divide-tensors%29" data-pltdoc="x"><span class="stt">floor-divide-tensors</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 1].floor-divide([tensor: 1]).data-now()
    is-roughly [list: 1]
  [tensor: 1, 3].floor-divide([tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].floor-divide([tensor: 5, 1]).data-now()
    is-roughly [list: 0, 3]
  [tensor: 1, 3, 4].floor-divide([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"

  [tensor: 1].floor-divide([tensor: 0])
    raises "The argument Tensor cannot contain 0"
  [tensor: 4.23].floor-divide([tensor: 7.65, 1.43, 0])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._615))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_max)" class="pyret-code"></a><span class="stt">.max</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns the maximum of the <span class="stt">Tensor</span> and <span class="pyret-highlight"><span class="stt">x</span></span>. This is equivalent to
<a href="#%28part._tensorflow_tensor-max%29" data-pltdoc="x"><span class="stt">tensor-max</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].max([tensor: 1]).data-now()
    is-roughly [list: 1]
  [tensor: 1, 3].max([tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].max([tensor: 200]).data-now()
    is-roughly [list: 200, 200]
  [tensor: 1, 3].max([tensor: 5, 1]).data-now()
    is-roughly [list: 5, 3]
  [tensor: 1, 3, 4].max([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._616))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_min)" class="pyret-code"></a><span class="stt">.min</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns the minimum of the <span class="stt">Tensor</span> and <span class="pyret-highlight"><span class="stt">x</span></span>. This is equivalent to
<a href="#%28part._tensorflow_tensor-min%29" data-pltdoc="x"><span class="stt">tensor-min</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].min([tensor: 1]).data-now()
    is-roughly [list: 0]
  [tensor: 1, 3].min([tensor: 1]).data-now()
    is-roughly [list: 1, 1]
  [tensor: 1, 3].min([tensor: 200]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].min([tensor: 0]).data-now()
    is-roughly [list: 0, 0]
  [tensor: 1, 3, 4].min([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._617))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_modulo)" class="pyret-code"></a><span class="stt">.modulo</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the modulo of the <span class="stt">Tensor</span> and <span class="pyret-highlight"><span class="stt">x</span></span>. This is equivalent to
<a href="#%28part._tensorflow_tensor-modulo%29" data-pltdoc="x"><span class="stt">tensor-modulo</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].modulo([tensor: 1]).data-now()
    is-roughly [list: 0]
  [tensor: 1, 3].modulo([tensor: 1]).data-now()
    is-roughly [list: 0, 0]
  [tensor: 1, 3].modulo([tensor: 5, 1]).data-now()
    is-roughly [list: 1, 0]
  [tensor: 1, 3, 4].modulo([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"

  [tensor: 1].modulo([tensor: 0])
    raises "The argument Tensor cannot contain 0"
  [tensor: 1].modulo([tensor: 1, 0])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._618))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_expt)" class="pyret-code"></a><span class="stt">.expt</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the power of the <span class="stt">Tensor</span> to <span class="pyret-highlight"><span class="stt">exponent</span></span>. This is
equivalent to <a href="#%28part._tensorflow_tensor-expt%29" data-pltdoc="x"><span class="stt">tensor-expt</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].expt([tensor: 1]).data-now()
    is-roughly [list: 0]
  [tensor: 1, 3].expt([tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  [tensor: 1, 3].expt([tensor: 4]).data-now()
    is-roughly [list: 1, 81]
  [tensor: 3, 3].expt([tensor: 5, 1]).data-now()
    is-roughly [list: 243, 3]
  [tensor: 1, 3, 4].expt([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._619))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor_shared._methods_squared-difference)" class="pyret-code"></a><span class="stt">.squared-difference</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes <span class="pyret-highlight"><span class="stt">(self - x) * (self - x)</span></span>, element-wise. This is
equivalent to <a href="#%28part._tensorflow_squared-difference%29" data-pltdoc="x"><span class="stt">squared-difference</span></a><span class="pyret-highlight"><span class="stt">(self, x)</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  [tensor: 0].squared-difference([tensor: 1]).data-now()
    is-roughly [list: 1]
  [tensor: 3].squared-difference([tensor: -3]).data-now()
    is-roughly [list: 36]
  [tensor: 1, 3].squared-difference([tensor: 4]).data-now()
    is-roughly [list: 9, 1]
  [tensor: 3, 3].squared-difference([tensor: 5, 1]).data-now()
    is-roughly [list: 4, 4]
  [tensor: 1, 3, 4].squared-difference([tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><h5>3.28.2<tt>&nbsp;</tt><a name="(part._.Tensor_.Operations)"></a>Tensor Operations</h5><h5>3.28.2.1<tt>&nbsp;</tt><a name="(part._.Arithmetic_.Operations)"></a>Arithmetic Operations</h5><p>All arithmetic operations are binary operations that accept two
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s as arguments. If the size of any axis in either
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> is greater than 1, the corresponding axis in the
other <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be the same size; otherwise, the operation
raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p># Valid operations:
add-tensors([tensor: 1], [tensor: 1])
add-tensors([tensor: 1, 2, 3], [tensor: 1])
add-tensors([tensor: 1, 2, 3, 4].as-2d(2, 2), [tensor: 1])
add-tensors([tensor: 1, 2], [tensor: 1, 2, 3, 4].as-2d(2, 2))
add-tensors([tensor: 1, 2].as-2d(2, 1), [tensor: 1, 2].as-2d(1, 2))
add-tensors([tensor: 1, 2, 3, 4].as-2d(2, 2), [tensor: 1, 2].as-2d(2, 1))

# Invalid operations:
add-tensors([tensor: 1, 2, 3], [tensor: 1, 2])
add-tensors([tensor: 1, 2].as-2d(2, 1), [tensor: 1, 2, 3].as-2d(3, 1))</p></pre></pre></div></p></div><p>In some cases, this behavior isn&rsquo;t intended, so most arithmetic operations
have a "strict" counterpart that raises an error if the two input
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s do not have the same shape.</p><p><a name="(idx._(gentag._620))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_add-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_add-tensors%29" data-pltdoc="x"><span class="stt">add-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Adds two <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s element-wise, A + B.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-add-tensors%29" data-pltdoc="x"><span class="stt">strict-add-tensors</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  add-tensors([tensor: 1], [tensor: 1]).data-now()
    is-roughly [list: 2]
  add-tensors([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 2, 4]
  add-tensors([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 6, 4]
  add-tensors([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._621))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_subtract-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_subtract-tensors%29" data-pltdoc="x"><span class="stt">subtract-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Subtracts two <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s element-wise, A &#8211; B.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-subtract-tensors%29" data-pltdoc="x"><span class="stt">strict-subtract-tensors</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  subtract-tensors([tensor: 1], [tensor: 1]).data-now()
    is-roughly [list: 0]
  subtract-tensors([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 0, 2]
  subtract-tensors([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: -4, 2]
  subtract-tensors([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._622))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_multiply-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_multiply-tensors%29" data-pltdoc="x"><span class="stt">multiply-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Multiplies two <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s element-wise, A * B.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-multiply-tensors%29" data-pltdoc="x"><span class="stt">strict-multiply-tensors</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  multiply-tensors([tensor: 1], [tensor: 1]).data-now()
    is-roughly [list: 1]
  multiply-tensors([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  multiply-tensors([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 5, 3]
  multiply-tensors([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._623))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_divide-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_divide-tensors%29" data-pltdoc="x"><span class="stt">divide-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Divides two <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s element-wise, A / B.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-divide-tensors%29" data-pltdoc="x"><span class="stt">strict-divide-tensors</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  divide-tensors([tensor: 1], [tensor: 1]).data-now()
    is-roughly [list: 1]
  divide-tensors([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  divide-tensors([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 0.2, 3]
  divide-tensors([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"

  divide-tensors([tensor: 1], [tensor: 0])
    raises "The argument Tensor cannot contain 0"
  divide-tensors([tensor: 4.23], [tensor: 7.65, 1.43, 0, 2.31])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._624))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_floor-divide-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_floor-divide-tensors%29" data-pltdoc="x"><span class="stt">floor-divide-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Divides two <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s element-wise, A / B, with the result
rounded with the floor function.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  floor-divide-tensors([tensor: 1], [tensor: 1]).data-now()
    is-roughly [list: 1]
  floor-divide-tensors([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  floor-divide-tensors([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 0, 3]
  floor-divide-tensors([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"

  floor-divide-tensors([tensor: 1], [tensor: 0])
    raises "The argument Tensor cannot contain 0"
  floor-divide-tensors([tensor: 4.23], [tensor: 7.65, 1.43, 0])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._625))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-max)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-max%29" data-pltdoc="x"><span class="stt">tensor-max</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing the maximum of <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span>, element-wise.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-tensor-max%29" data-pltdoc="x"><span class="stt">strict-tensor-max</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-max([tensor: 0], [tensor: 1]).data-now()
    is-roughly [list: 1]
  tensor-max([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 1, 3]
  tensor-max([tensor: 1, 3], [tensor: 200]).data-now()
    is-roughly [list: 200, 200]
  tensor-max([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 5, 3]
  tensor-max([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._626))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-min)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-min%29" data-pltdoc="x"><span class="stt">tensor-min</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing the minimum of <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span>, element-wise.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-tensor-min%29" data-pltdoc="x"><span class="stt">strict-tensor-min</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-min([tensor: 0], [tensor: 1]).data-now()
    is-roughly [list: 0]
  tensor-min([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 1, 1]
  tensor-min([tensor: 1, 3], [tensor: 200]).data-now()
    is-roughly [list: 1, 3]
  tensor-min([tensor: 1, 3], [tensor: 0]).data-now()
    is-roughly [list: 0, 0]
  tensor-min([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 1, 1]
  tensor-min([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._627))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-modulo)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-modulo%29" data-pltdoc="x"><span class="stt">tensor-modulo</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the modulo of <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span>, element-wise.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-tensor-modulo%29" data-pltdoc="x"><span class="stt">strict-tensor-modulo</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-modulo([tensor: 0], [tensor: 1]).data-now()
    is-roughly [list: 0]
  tensor-modulo([tensor: 1, 3], [tensor: 1]).data-now()
    is-roughly [list: 0, 0]
  tensor-modulo([tensor: 1, 3], [tensor: 200]).data-now()
    is-roughly [list: 1, 3]
  tensor-modulo([tensor: 1, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 1, 0]
  tensor-modulo([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._628))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-expt)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-expt%29" data-pltdoc="x"><span class="stt">tensor-expt</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">base</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">exponent</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the power of <span class="pyret-highlight"><span class="stt">base</span></span> to <span class="pyret-highlight"><span class="stt">exponent</span></span>, element-wise.</p><p>To ensure that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-tensor-expt%29" data-pltdoc="x"><span class="stt">strict-tensor-expt</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-expt([tensor: 0], [tensor: 1]).data-now()
    is-roughly [list: 0]
  tensor-expt([tensor: 3], [tensor: -3]).data-now()
    is-roughly [list: 0.03703703]
  tensor-expt([tensor: 1, 3], [tensor: 4]).data-now()
    is-roughly [list: 1, 81]
  tensor-expt([tensor: 3, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 243, 3]
  tensor-expt([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._629))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_squared-difference)" class="pyret-code"></a><a href="#%28part._tensorflow_squared-difference%29" data-pltdoc="x"><span class="stt">squared-difference</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes <span class="pyret-highlight"><span class="stt">(a - b) * (a - b)</span></span>, element-wise.</p><p>To assert that <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span> are the same shape, use
<a href="#%28part._tensorflow_strict-squared-difference%29" data-pltdoc="x"><span class="stt">strict-squared-difference</span></a>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  squared-difference([tensor: 0], [tensor: 1]).data-now()
    is-roughly [list: 1]
  squared-difference([tensor: 3], [tensor: -3]).data-now()
    is-roughly [list: 36]
  squared-difference([tensor: 1, 3], [tensor: 4]).data-now()
    is-roughly [list: 9, 1]
  squared-difference([tensor: 3, 3], [tensor: 5, 1]).data-now()
    is-roughly [list: 4, 4]
  squared-difference([tensor: 1, 3, 4], [tensor: 5, 1])
    raises "Tensors could not be applied as binary operation arguments"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._630))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-add-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-add-tensors%29" data-pltdoc="x"><span class="stt">strict-add-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_add-tensors%29" data-pltdoc="x"><span class="stt">add-tensors</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-add-tensors([tensor: 1], [tensor: 0])
    is-roughly add-tensors([tensor: 1], [tensor: 0])
  strict-add-tensors([tensor: -4, -1], [tensor: -8, -2])
    is-roughly add-tensors([tensor: -4, -1], [tensor: -8, -2])

  strict-add-tensors([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-add-tensors([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._631))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-subtract-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-subtract-tensors%29" data-pltdoc="x"><span class="stt">strict-subtract-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_subtract-tensors%29" data-pltdoc="x"><span class="stt">subtract-tensors</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-subtract-tensors([tensor: 1], [tensor: 0])
    is-roughly subtract-tensors([tensor: 1], [tensor: 0])
  strict-subtract-tensors([tensor: -4, -1], [tensor: -8, -2])
    is-roughly subtract-tensors([tensor: -4, -1], [tensor: -8, -2])

  strict-subtract-tensors([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-subtract-tensors([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._632))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-multiply-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-multiply-tensors%29" data-pltdoc="x"><span class="stt">strict-multiply-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_multiply-tensors%29" data-pltdoc="x"><span class="stt">multiply-tensors</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-multiply-tensors([tensor: 1], [tensor: 0])
    is-roughly multiply-tensors([tensor: 1], [tensor: 0])
  strict-multiply-tensors([tensor: -4, -1], [tensor: -8, -2])
    is-roughly multiply-tensors([tensor: -4, -1], [tensor: -8, -2])

  strict-multiply-tensors([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-multiply-tensors([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._633))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-divide-tensors)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-divide-tensors%29" data-pltdoc="x"><span class="stt">strict-divide-tensors</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_divide-tensors%29" data-pltdoc="x"><span class="stt">divide-tensors</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-divide-tensors([tensor: 1], [tensor: 0])
    is-roughly divide-tensors([tensor: 1], [tensor: 0])
  strict-divide-tensors([tensor: -4, -1], [tensor: -8, -2])
    is-roughly divide-tensors([tensor: -4, -1], [tensor: -8, -2])

  strict-divide-tensors([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-divide-tensors([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"

  strict-divide-tensors([tensor: 1], [tensor: 0])
    raises "The argument Tensor cannot contain 0"
  strict-divide-tensors([tensor: 1, 1], [tensor: 1, 0])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._634))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-tensor-max)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-tensor-max%29" data-pltdoc="x"><span class="stt">strict-tensor-max</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_tensor-max%29" data-pltdoc="x"><span class="stt">tensor-max</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-tensor-max([tensor: 1], [tensor: 0])
    is-roughly tensor-max([tensor: 1], [tensor: 0])
  strict-tensor-max([tensor: -4, -1], [tensor: -8, -2])
    is-roughly tensor-max([tensor: -4, -1], [tensor: -8, -2])

  strict-tensor-max([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-tensor-max([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._635))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-tensor-min)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-tensor-min%29" data-pltdoc="x"><span class="stt">strict-tensor-min</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_tensor-min%29" data-pltdoc="x"><span class="stt">tensor-min</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-tensor-min([tensor: 1], [tensor: 0])
    is-roughly tensor-min([tensor: 1], [tensor: 0])
  strict-tensor-min([tensor: -4, -1], [tensor: -8, -2])
    is-roughly tensor-min([tensor: -4, -1], [tensor: -8, -2])

  strict-tensor-min([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-tensor-min([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._636))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-tensor-expt)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-tensor-expt%29" data-pltdoc="x"><span class="stt">strict-tensor-expt</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_tensor-expt%29" data-pltdoc="x"><span class="stt">tensor-expt</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-tensor-expt([tensor: 1], [tensor: 0])
    is-roughly tensor-expt([tensor: 1], [tensor: 0])
  strict-tensor-expt([tensor: -4, -1], [tensor: -8, -2])
    is-roughly tensor-expt([tensor: -4, -1], [tensor: -8, -2])

  strict-tensor-expt([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-tensor-expt([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._637))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-tensor-modulo)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-tensor-modulo%29" data-pltdoc="x"><span class="stt">strict-tensor-modulo</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_tensor-modulo%29" data-pltdoc="x"><span class="stt">tensor-modulo</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span> and
<span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-tensor-modulo([tensor: 1], [tensor: 0])
    is-roughly tensor-modulo([tensor: 1], [tensor: 0])
  strict-tensor-modulo([tensor: -4, -1], [tensor: -8, -2])
    is-roughly tensor-modulo([tensor: -4, -1], [tensor: -8, -2])

  strict-tensor-modulo([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-tensor-modulo([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"

  strict-tensor-modulo([tensor: 1], [tensor: 0])
    raises "The argument Tensor cannot contain 0"
  strict-tensor-modulo([tensor: 1, 1], [tensor: 1, 0])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._638))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_strict-squared-difference)" class="pyret-code"></a><a href="#%28part._tensorflow_strict-squared-difference%29" data-pltdoc="x"><span class="stt">strict-squared-difference</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Same as <a href="#%28part._tensorflow_squared-difference%29" data-pltdoc="x"><span class="stt">squared-difference</span></a>, but raises an error if <span class="pyret-highlight"><span class="stt">a</span></span>
and <span class="pyret-highlight"><span class="stt">b</span></span> are not the same shape (as determined by
<a href="#%28part._tensorflow_.Tensor_shared._methods_shape%29" data-pltdoc="x"><span class="stt">.shape</span></a>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  strict-squared-difference([tensor: 1], [tensor: 0])
    is-roughly squared-difference([tensor: 1], [tensor: 0])
  strict-squared-difference([tensor: -4, -1], [tensor: -8, -2])
    is-roughly squared-difference([tensor: -4, -1], [tensor: -8, -2])

  strict-squared-difference([tensor: 1], [tensor: 1, 2])
    raises "The first tensor does not have the same shape as the second tensor"
  strict-squared-difference([tensor: 8, 0].as-2d(2, 1), [tensor: 3, 1])
    raises "The first tensor does not have the same shape as the second tensor"
end</p></pre></pre></div></p></div><h5>3.28.2.2<tt>&nbsp;</tt><a name="(part._.Trigonometry_.Operations)"></a>Trigonometry Operations</h5><p><a name="(idx._(gentag._639))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-acos)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-acos%29" data-pltdoc="x"><span class="stt">tensor-acos</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse cosine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p>All of the values in the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be between
<span class="pyret-highlight"><span class="stt">-1</span></span> and <span class="pyret-highlight"><span class="stt">1</span></span>, inclusive; otherwise, the function raises an
error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-acos([tensor: 1]).data-now() is-roughly [list: 0]
  tensor-acos([tensor: 0]).data-now() is-roughly [list: ~1.5707963]
  tensor-acos([tensor: -1]).data-now() is-roughly [list: ~3.1415927]
  tensor-acos([tensor: 0.5, 0.2, 0.6]).data-now()
    is-roughly [list: ~1.0471975, ~1.3694384, ~0.9272952]

  tensor-acos([tensor: 10])
    raises "Values in the input Tensor must be between -1 and 1, inclusive"
  tensor-acos([tensor: -1, 0, 16, -2])
    raises "Values in the input Tensor must be between -1 and 1, inclusive"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._640))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-acosh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-acosh%29" data-pltdoc="x"><span class="stt">tensor-acosh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse hyperbolic cosine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise.</p><p>All of the values in the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be greater than
or equal to <span class="pyret-highlight"><span class="stt">1</span></span>; otherwise, the function raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-acosh([tensor: 1]).data-now() is-roughly [list: 0]
  tensor-acosh([tensor: 2]).data-now() is-roughly [list: ~1.3169579]
  tensor-acosh([tensor: 1, 5, 10, 200]).data-now()
    is-roughly [list: ~0, ~2.2924315, ~2.9932229, ~5.9914584]

  tensor-acosh([tensor: 0])
    raises "Values in the input Tensor must be at least 1"
  tensor-acosh([tensor: 4, 1, 10, 32, -2, 82])
    raises "Values in the input Tensor must be at least 1"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._641))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-asin)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-asin%29" data-pltdoc="x"><span class="stt">tensor-asin</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse sine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p>All of the values in the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be between
<span class="pyret-highlight"><span class="stt">-1</span></span> and <span class="pyret-highlight"><span class="stt">1</span></span>, inclusive; otherwise, the function raises an
error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  # Check one-dimensional usages:
  tensor-asin([tensor: 1]).data-now() is-roughly [list: ~1.5707963]
  tensor-asin([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-asin([tensor: -0.5]).data-now() is-roughly [list: ~-0.5235987]
  tensor-asin([tensor: 0.5, 0.2, 0.6]).data-now()
    is-roughly [list: ~0.5235987, ~0.2013579, ~0.6435011]

  # Check bounding values:
  tensor-asin([tensor: 9])
    raises "Values in the input Tensor must be between -1 and 1, inclusive"
  tensor-asin([tensor: -1, -2, -3])
    raises "Values in the input Tensor must be between -1 and 1, inclusive"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._642))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-asinh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-asinh%29" data-pltdoc="x"><span class="stt">tensor-asinh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse hyperbolic sine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-asinh([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-asinh([tensor: 1]).data-now() is-roughly [list: ~0.8813736]
  tensor-asinh([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~-0.8813736, ~-1.4436353, ~-1.8184462]
  tensor-asinh([tensor: 21, 0, 32, 2]).data-now()
    is-roughly [list: ~3.7382359, ~0, ~4.1591272, ~1.4436354]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._643))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-atan)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-atan%29" data-pltdoc="x"><span class="stt">tensor-atan</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse tangent of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-atan([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-atan([tensor: 1]).data-now() is-roughly [list: ~0.7853981]
  tensor-atan([tensor: -1]).data-now() is-roughly [list: ~-0.7853981]
  tensor-atan([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~-0.7853981, ~-1.1071487, ~-1.2490458]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._644))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-atan2)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-atan2%29" data-pltdoc="x"><span class="stt">tensor-atan2</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">a</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">b</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the <a href="https://en.wikipedia.org/wiki/Atan2">four-quadrant inverse tangent</a> of <span class="pyret-highlight"><span class="stt">a</span></span> and <span class="pyret-highlight"><span class="stt">b</span></span>, element-wise.</p><p><a name="(idx._(gentag._645))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-atanh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-atanh%29" data-pltdoc="x"><span class="stt">tensor-atanh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the inverse hyperbolic tangent of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise.</p><p>All of the values in the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be between
<span class="pyret-highlight"><span class="stt">-1</span></span> and <span class="pyret-highlight"><span class="stt">1</span></span>, exclusive; otherwise, the function raises an
error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  # Check one-dimensional usages:
  tensor-atanh([tensor: 0.5]).data-now() is-roughly [list: ~0.5493061]
  tensor-atanh([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-atanh([tensor: -0.9]).data-now() is-roughly [list: ~-1.4722193]
  tensor-atanh([tensor: 0.5, 0.2, 0.6]).data-now()
    is-roughly [list: ~0.5493061, ~0.2027325, ~0.6931471]

  # Check bounding values:
  tensor-atanh([tensor: 1])
    raises "Values in the input Tensor must be between -1 and 1, exclusive"
  tensor-atanh([tensor: -1])
    raises "Values in the input Tensor must be between -1 and 1, exclusive"
  tensor-atanh([tensor: 0, 16, -1, 9, 1])
    raises "Values in the input Tensor must be between -1 and 1, exclusive"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._646))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-cos)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-cos%29" data-pltdoc="x"><span class="stt">tensor-cos</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the cosine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-cos([tensor: 0]).data-now() is-roughly [list: 1]
  tensor-cos([tensor: 1]).data-now() is-roughly [list: ~0.5403115]
  tensor-cos([tensor: -1]).data-now() is-roughly [list: ~0.5403116]
  tensor-cos([tensor: 6, 2, -4]).data-now()
    is-roughly [list: ~0.9601798, ~-0.4161523, ~-0.6536576]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._647))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-cosh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-cosh%29" data-pltdoc="x"><span class="stt">tensor-cosh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the hyperbolic cosine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-cosh([tensor: 0]).data-now() is-roughly [list: 1]
  tensor-cosh([tensor: 1]).data-now() is-roughly [list: ~1.5430805]
  tensor-cosh([tensor: -1]).data-now() is-roughly [list: ~1.5430805]
  tensor-cosh([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~1.5430805, ~3.7621955, ~10.0676612]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._648))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-sin)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-sin%29" data-pltdoc="x"><span class="stt">tensor-sin</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the sine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-sin([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-sin([tensor: 1]).data-now() is-roughly [list: ~0.8414709]
  tensor-sin([tensor: -1]).data-now() is-roughly [list: ~-0.8415220]
  tensor-sin([tensor: 6, 2, -4]).data-now()
    is-roughly [list: ~-0.2794162, ~0.9092976, ~0.7568427]
  tensor-sin([tensor: 21, 0, 32, 2]).data-now()
    is-roughly [list: ~0.8366656, ~0, ~0.5514304, ~0.9092976]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._649))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-sinh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-sinh%29" data-pltdoc="x"><span class="stt">tensor-sinh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the hyperbolic sine of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-sinh([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-sinh([tensor: 1]).data-now() is-roughly [list: ~1.1752011]
  tensor-sinh([tensor: -1]).data-now() is-roughly [list: ~-1.1752011]
  tensor-sinh([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~-1.1752011, ~-3.6268603, ~-10.0178737]
  tensor-sinh([tensor: 6, 2, -4]).data-now()
    is-roughly [list: ~201.7131195, ~3.6268601, ~-27.2899169]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._650))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-tan)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-tan%29" data-pltdoc="x"><span class="stt">tensor-tan</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the tangent of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-tan([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-tan([tensor: 1]).data-now() is-roughly [list: ~1.5573809]
  tensor-tan([tensor: -1]).data-now() is-roughly [list: ~-1.5573809]
  tensor-tan([tensor: 21, 0, 32, 2]).data-now()
    is-roughly [list: ~-1.5275151, ~0, ~0.6610110, ~-2.1850113]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._651))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-tanh)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-tanh%29" data-pltdoc="x"><span class="stt">tensor-tanh</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the hyperbolic tangent of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-tanh([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-tanh([tensor: 1]).data-now() is-roughly [list: ~0.7615941]
  tensor-tanh([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~-0.7615941, ~-0.9640275, ~-0.9950547]
  tensor-tanh([tensor: 6, 2, -4]).data-now()
    is-roughly [list: ~0.9999876, ~0.9640275, ~-0.9993293]
end</p></pre></pre></div></p></div><h5>3.28.2.3<tt>&nbsp;</tt><a name="(part._.Math_.Operations)"></a>Math Operations</h5><p><a name="(idx._(gentag._652))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-abs)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-abs%29" data-pltdoc="x"><span class="stt">tensor-abs</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the absolute value of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-abs([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-abs([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-abs([tensor: -1]).data-now() is-roughly [list: 1]
  tensor-abs([tensor: -1, -2, -3]).data-now() is-roughly [list: 1, 2, 3]

  two-dim-abs = tensor-abs([tensor: -4, 5, -6, -7, -8, 9].as-2d(3, 2))
  two-dim-abs.shape() is [list: 3, 2]
  two-dim-abs.data-now() is-roughly [list: 4, 5, 6, 7, 8, 9]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._653))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-ceil)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-ceil%29" data-pltdoc="x"><span class="stt">tensor-ceil</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the ceiling of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  # Check usages on integer tensors:
  tensor-ceil([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-ceil([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-ceil([tensor: -1, -2, -3]).data-now() is-roughly [list: -1, -2, -3]

  # Check usages on float tensors:
  tensor-ceil([tensor: 0.3]).data-now() is-roughly [list: 1]
  tensor-ceil([tensor: 0.5]).data-now() is-roughly [list: 1]
  tensor-ceil([tensor: 0.8]).data-now() is-roughly [list: 1]
  tensor-ceil([tensor: -0.2]).data-now() is-roughly [list: 0]
  tensor-ceil([tensor: -0.5]).data-now() is-roughly [list: 0]
  tensor-ceil([tensor: -0.9]).data-now() is-roughly [list: 0]
  tensor-ceil([tensor: 3.5, 5.2, 1.6]).data-now() is-roughly [list: 4, 6, 2]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._654))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_clip-by-value)" class="pyret-code"></a><a href="#%28part._tensorflow_clip-by-value%29" data-pltdoc="x"><span class="stt">clip-by-value</span></a> :: (</dt><dt class="indent-arg"><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">min-value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">max-value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Clips the values of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise, such that every
element in the resulting <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> is at least <span class="pyret-highlight"><span class="stt">min-value</span></span>
and is at most <span class="pyret-highlight"><span class="stt">max-value</span></span>.</p><p><span class="pyret-highlight"><span class="stt">min-value</span></span> must be less than or equal to <span class="pyret-highlight"><span class="stt">max-value</span></span>; otherwise,
the function raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  clip-by-value([tensor: 0], 0, 0).data-now() is-roughly [list: 0]
  clip-by-value([tensor: 0], -1, 1).data-now() is-roughly [list: 0]
  clip-by-value([tensor: 0], 1, 4).data-now() is-roughly [list: 1]
  clip-by-value([tensor: 21, 0, 32, 2], 4, 9).data-now()
    is-roughly [list: 9, 4, 9, 4]
  clip-by-value([tensor: 3, 9, 10, 3.24], 4.5, 9.4).data-now()
    is-roughly [list: 4.5, 9, 9.4, 4.5]

  clip-by-value([tensor: 1], 10, 0)
    raises "minimum value to clip to must be less than or equal to the maximum"
  clip-by-value([tensor: 1], -10, -45)
    raises "minimum value to clip to must be less than or equal to the maximum"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._655))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_exponential-linear-units)" class="pyret-code"></a><a href="#%28part._tensorflow_exponential-linear-units%29" data-pltdoc="x"><span class="stt">exponential-linear-units</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#ELUs">exponential linear units</a> function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._656))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_elu)" class="pyret-code"></a><a href="#%28part._tensorflow_elu%29" data-pltdoc="x"><span class="stt">elu</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Alias for <a href="#%28part._tensorflow_exponential-linear-units%29" data-pltdoc="x"><span class="stt">exponential-linear-units</span></a>.</p><p><a name="(idx._(gentag._657))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_gauss-error)" class="pyret-code"></a><a href="#%28part._tensorflow_gauss-error%29" data-pltdoc="x"><span class="stt">gauss-error</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the <a href="http://mathworld.wolfram.com/Erf.html">gauss error function</a> to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._658))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_erf)" class="pyret-code"></a><a href="#%28part._tensorflow_erf%29" data-pltdoc="x"><span class="stt">erf</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Alias for <a href="#%28part._tensorflow_gauss-error%29" data-pltdoc="x"><span class="stt">gauss-error</span></a>.</p><p><a name="(idx._(gentag._659))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-exp)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-exp%29" data-pltdoc="x"><span class="stt">tensor-exp</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the equivalent of <span class="pyret-highlight"><span class="stt">num-exp(tensor)</span></span>, element-wise.</p><p><a name="(idx._(gentag._660))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-exp-min1)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-exp-min1%29" data-pltdoc="x"><span class="stt">tensor-exp-min1</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the equivalent of <span class="pyret-highlight"><span class="stt">num-exp(tensor - 1)</span></span>, element-wise.</p><p><a name="(idx._(gentag._661))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-floor)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-floor%29" data-pltdoc="x"><span class="stt">tensor-floor</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the floor of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  # Check usages on integer tensors:
  tensor-floor([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-floor([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-floor([tensor: -1]).data-now() is-roughly [list: -1]
  tensor-floor([tensor: -1, -2, -3]).data-now() is-roughly [list: -1, -2, -3]

  # Check usages on float tensors:
  tensor-floor([tensor: 0.3]).data-now() is-roughly [list: 0]
  tensor-floor([tensor: 0.5]).data-now() is-roughly [list: 0]
  tensor-floor([tensor: 0.8]).data-now() is-roughly [list: 0]
  tensor-floor([tensor: 0.999]).data-now() is-roughly [list: 0]
  tensor-floor([tensor: 1.1]).data-now() is-roughly [list: 1]
  tensor-floor([tensor: -0.2]).data-now() is-roughly [list: -1]
  tensor-floor([tensor: -0.5]).data-now() is-roughly [list: -1]
  tensor-floor([tensor: -0.9]).data-now() is-roughly [list: -1]
  tensor-floor([tensor: 3.5, 5.2, 1.6]).data-now() is-roughly [list: 3, 5, 1]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._662))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_leaky-relu)" class="pyret-code"></a><a href="#%28part._tensorflow_leaky-relu%29" data-pltdoc="x"><span class="stt">leaky-relu</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">alpha</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLUs">leaky rectified linear units</a> function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise.</p><p><span class="pyret-highlight"><span class="stt">alpha</span></span> is the scaling factor for negative values. The default in
TensorFlow.js is <span class="pyret-highlight"><span class="stt">0.2</span></span>, but the argument has been exposed here for more
flexibility.</p><p><a name="(idx._(gentag._663))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-log)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-log%29" data-pltdoc="x"><span class="stt">tensor-log</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the natural logarithm of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise; that
is, it computes the equivalent of <span class="pyret-highlight"><span class="stt">num-log(tensor)</span></span>.</p><p><a name="(idx._(gentag._664))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-log-plus1)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-log-plus1%29" data-pltdoc="x"><span class="stt">tensor-log-plus1</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the natural logarithm of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> plus 1,
element-wise; that is, it computes the equivalent of
<span class="pyret-highlight"><span class="stt">num-log(tensor + 1)</span></span>.</p><p><a name="(idx._(gentag._665))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_log-sigmoid)" class="pyret-code"></a><a href="#%28part._tensorflow_log-sigmoid%29" data-pltdoc="x"><span class="stt">log-sigmoid</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the <a href="https://en.wikibooks.org/wiki/Artificial_Neural_Networks/
  Activation_Functions#Continuous_Log-Sigmoid_Function">log sigmoid</a> function
to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._666))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-negate)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-negate%29" data-pltdoc="x"><span class="stt">tensor-negate</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Multiplies each element in the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> by <span class="pyret-highlight"><span class="stt">-1</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-negate([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-negate([tensor: 1]).data-now() is-roughly [list: -1]
  tensor-negate([tensor: -1]).data-now() is-roughly [list: 1]
  tensor-negate([tensor: -1, 2, 3, -4, 5]).data-now()
    is-roughly [list: 1, -2, -3, 4, -5]
  tensor-negate([tensor: -1, -2, -3, -4, -5]).data-now()
    is-roughly [list: 1, 2, 3, 4, 5]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._667))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_parametric-relu)" class="pyret-code"></a><a href="#%28part._tensorflow_parametric-relu%29" data-pltdoc="x"><span class="stt">parametric-relu</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">alpha</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLUs">leaky rectified linear units</a> function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise, using parametric alphas.</p><p><span class="pyret-highlight"><span class="stt">alpha</span></span> is the scaling factor for negative values.</p><p><a name="(idx._(gentag._668))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-reciprocal)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-reciprocal%29" data-pltdoc="x"><span class="stt">tensor-reciprocal</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the reciprocal of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise; that is, it
computes the equivalent of <span class="pyret-highlight"><span class="stt">1 / tensor</span></span>.</p><p>In order to avoid division-by-zero errors, the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>
cannot contain <span class="pyret-highlight"><span class="stt">0</span></span>; otherwise, the function raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-reciprocal([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-reciprocal([tensor: -1]).data-now() is-roughly [list: -1]
  tensor-reciprocal([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~-1, ~-0.5, ~-0.3333333]

  # Check for division-by-zero errors:
  tensor-reciprocal([tensor: 0])
    raises "The argument Tensor cannot contain 0"
  tensor-reciprocal([tensor: 1, 0])
    raises "The argument Tensor cannot contain 0"
  tensor-reciprocal([tensor: 7.65, 0, 1.43])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._669))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_relu)" class="pyret-code"></a><a href="#%28part._tensorflow_relu%29" data-pltdoc="x"><span class="stt">relu</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">rectified linear units</a> function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._670))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-round)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-round%29" data-pltdoc="x"><span class="stt">tensor-round</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the equivalent of <span class="pyret-highlight"><span class="stt">num-round(tensor)</span></span>, element-wise.</p><p>Due to unavoidable precision errors on <span class="pyret-highlight"><span class="stt">Roughnum</span></span>s, the behavior for
numbers ending in <span class="stt">.5</span> is inconsistent. See the examples below.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-round([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-round([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-round([tensor: -1]).data-now() is-roughly [list: -1]
  tensor-round([tensor: 0.1]).data-now() is-roughly [list: 0]
  tensor-round([tensor: 0.3]).data-now() is-roughly [list: 0]
  tensor-round([tensor: 0.8]).data-now() is-roughly [list: 1]
  tensor-round([tensor: 0.999]).data-now() is-roughly [list: 1]
  tensor-round([tensor: -1, -2, -3]).data-now() is-roughly [list: -1, -2, -3]
  tensor-round([tensor: 3.5, 5.2, 1.6]).data-now() is-roughly [list: 4, 5, 2]

  # Note inconsistent behavior with rounding on Roughnums:
  tensor-round([tensor: 0.5]).data-now() is-roughly [list: 0] # rounds down
  tensor-round([tensor: 3.5]).data-now() is-roughly [list: 4] # rounds up
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._671))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reciprocal-sqrt)" class="pyret-code"></a><a href="#%28part._tensorflow_reciprocal-sqrt%29" data-pltdoc="x"><span class="stt">reciprocal-sqrt</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the recriprocal of the square root of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>,
element-wise.</p><p>The resulting <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> is roughly equivalent to
<span class="pyret-highlight"><span class="stt">tensor-reciprocal(tensor-sqrt(tensor))</span></span>.</p><p>In order to avoid division-by-zero errors, the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>
cannot contain <span class="pyret-highlight"><span class="stt">0</span></span>; otherwise, the function raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  reciprocal-sqrt([tensor: 1]).data-now() is-roughly [list: 1]
  reciprocal-sqrt([tensor: -1]).data-now() is-roughly [list: 1]
  reciprocal-sqrt([tensor: -1, -2, -3]).data-now()
    is-roughly [list: ~1, ~0.7071067, ~0.5773502]
  reciprocal-sqrt([tensor: 6, 2, -4]).data-now()
    is-roughly [list: ~0.4082482, ~0.7071067, ~0.5]

  # Check for division-by-zero errors:
  reciprocal-sqrt([tensor: 0])
    raises "The argument Tensor cannot contain 0"
  reciprocal-sqrt([tensor: 1, 0])
    raises "The argument Tensor cannot contain 0"
  reciprocal-sqrt([tensor: 7.65, 0, 1.43])
    raises "The argument Tensor cannot contain 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._672))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_scaled-elu)" class="pyret-code"></a><a href="#%28part._tensorflow_scaled-elu%29" data-pltdoc="x"><span class="stt">scaled-elu</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies a scaled, exponential linear units function to the
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._673))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_sigmoid)" class="pyret-code"></a><a href="#%28part._tensorflow_sigmoid%29" data-pltdoc="x"><span class="stt">sigmoid</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the sigmoid function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p><a name="(idx._(gentag._674))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_signed-ones)" class="pyret-code"></a><a href="#%28part._tensorflow_signed-ones%29" data-pltdoc="x"><span class="stt">signed-ones</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns an element-wise indication of the sign of each number in the
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>; that is, every value in the original tensor is
represented in the resulting tensor as <span class="pyret-highlight"><span class="stt">~+1</span></span> if the value is positive,
<span class="pyret-highlight"><span class="stt">~-1</span></span> if the value was negative, or <span class="pyret-highlight"><span class="stt">~0</span></span> if the value was zero
or not a number.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  signed-ones([tensor: 0]).data-now() is-roughly [list: 0]
  signed-ones([tensor: 1]).data-now() is-roughly [list: 1]
  signed-ones([tensor: 3]).data-now() is-roughly [list: 1]
  signed-ones([tensor: -1]).data-now() is-roughly [list: -1]
  signed-ones([tensor: -5]).data-now() is-roughly [list: -1]
  signed-ones([tensor: 9, -7, 5, -3, -1, 0]).data-now()
    is-roughly [list: 1, -1, 1, -1, -1, 0]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._675))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_softplus)" class="pyret-code"></a><a href="#%28part._tensorflow_softplus%29" data-pltdoc="x"><span class="stt">softplus</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the softplus function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p>See <a href="https://sefiks.com/2017/08/11/softplus-as-a-neural-networks-activation-function/">https://sefiks.com/2017/08/11/softplus-as-a-neural-networks-activation-function/</a>
for more information.</p><p><a name="(idx._(gentag._676))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-sqrt)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-sqrt%29" data-pltdoc="x"><span class="stt">tensor-sqrt</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the square root of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><p>All of the values in the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> must be greater than
or equal to <span class="pyret-highlight"><span class="stt">0</span></span>; otherwise, the function raises an error.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-sqrt([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-sqrt([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-sqrt([tensor: 4]).data-now() is-roughly [list: 2]
  tensor-sqrt([tensor: 9]).data-now() is-roughly [list: 3]
  tensor-sqrt([tensor: 25]).data-now() is-roughly [list: 5]

  tensor-sqrt([tensor: -1]).data-now()
    raises "Values in the input Tensor must be at least 0"
  tensor-sqrt([tensor: 9, -7, 5, -3, -1, 0, 0.5]).data-now()
    raises "Values in the input Tensor must be at least 0"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._677))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tensor-square)" class="pyret-code"></a><a href="#%28part._tensorflow_tensor-square%29" data-pltdoc="x"><span class="stt">tensor-square</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes the square of the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  tensor-square([tensor: 0]).data-now() is-roughly [list: 0]
  tensor-square([tensor: 1]).data-now() is-roughly [list: 1]
  tensor-square([tensor: 5]).data-now() is-roughly [list: 25]
  tensor-square([tensor: -1]).data-now() is-roughly [list: 1]
  tensor-square([tensor: -3]).data-now() is-roughly [list: 9]
  tensor-square([tensor: 9, -7, 5, -3, -1, 0, 0.5]).data-now()
    is-roughly [list: 81, 49, 25, 9, 1, 0, 0.25]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._678))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_step)" class="pyret-code"></a><a href="#%28part._tensorflow_step%29" data-pltdoc="x"><span class="stt">step</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies the unit step function to the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, element-wise;
that is, every value in the original tensor is represented in the resulting
tensor as <span class="pyret-highlight"><span class="stt">~+1</span></span> if the value is positive; otherwise, it is represented
as <span class="pyret-highlight"><span class="stt">~0</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  step([tensor: 0]).data-now() is-roughly [list: 0]
  step([tensor: 1]).data-now() is-roughly [list: 1]
  step([tensor: 5]).data-now() is-roughly [list: 1]
  step([tensor: -1]).data-now() is-roughly [list: 0]
  step([tensor: -3]).data-now() is-roughly [list: 0]
  step([tensor: -1, 4, 0, 0, 15, -43, 0]).data-now()
    is-roughly [list: 0, 1, 0, 0, 1, 0, 0]
end</p></pre></pre></div></p></div><h5>3.28.2.4<tt>&nbsp;</tt><a name="(part._.Reduction_.Operations)"></a>Reduction Operations</h5><p><a name="(idx._(gentag._679))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_arg-max)" class="pyret-code"></a><a href="#%28part._tensorflow_arg-max%29" data-pltdoc="x"><span class="stt">arg-max</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a new <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> where each element is the index of the maximum
values along the outermost dimension of <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><p><a name="(idx._(gentag._680))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_arg-min)" class="pyret-code"></a><a href="#%28part._tensorflow_arg-min%29" data-pltdoc="x"><span class="stt">arg-min</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a new <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> where each element is the index of the minimum
values along the outermost dimension of <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><p><a name="(idx._(gentag._681))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_log-sum-exp)" class="pyret-code"></a><a href="#%28part._tensorflow_log-sum-exp%29" data-pltdoc="x"><span class="stt">log-sum-exp</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Computes <span class="pyret-highlight"><span class="stt">log(sum(exp(elements along the outermost dimension))</span></span>.</p><p>Reduces <span class="pyret-highlight"><span class="stt">tensor</span></span> along the outermost dimension.</p><p><a name="(idx._(gentag._682))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-all)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-all%29" data-pltdoc="x"><span class="stt">reduce-all</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Reduces the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> across all dimensions by computing the
logical "and" of its elements.</p><p><span class="pyret-highlight"><span class="stt">tensor</span></span> must be of type <span class="pyret-highlight"><span class="stt">"bool"</span></span>; otherwise, the function raises
an error.</p><p><a name="(idx._(gentag._683))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-any)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-any%29" data-pltdoc="x"><span class="stt">reduce-any</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Reduces the input <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> across all dimensions by computing the
logical "or" of its elements.</p><p><span class="pyret-highlight"><span class="stt">tensor</span></span> must be of type <span class="pyret-highlight"><span class="stt">"bool"</span></span>; otherwise, the function raises
an error.</p><p><a name="(idx._(gentag._684))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-max)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-max%29" data-pltdoc="x"><span class="stt">reduce-max</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing a single value that is the maximum value
of all entries in <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><p><a name="(idx._(gentag._685))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-min)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-min%29" data-pltdoc="x"><span class="stt">reduce-min</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing a single value that is the minimum value
of all entries in <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><p><a name="(idx._(gentag._686))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-mean)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-mean%29" data-pltdoc="x"><span class="stt">reduce-mean</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing a single value that is the mean value
of all entries in <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><p><a name="(idx._(gentag._687))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reduce-sum)" class="pyret-code"></a><a href="#%28part._tensorflow_reduce-sum%29" data-pltdoc="x"><span class="stt">reduce-sum</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> containing a single value that is the sum
of all entries in <span class="pyret-highlight"><span class="stt">tensor</span></span>.</p><h5>3.28.2.5<tt>&nbsp;</tt><a name="(part._.Slicing_and_.Joining_.Operations)"></a>Slicing and Joining Operations</h5><p><a name="(idx._(gentag._688))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_concatenate)" class="pyret-code"></a><a href="#%28part._tensorflow_concatenate%29" data-pltdoc="x"><span class="stt">concatenate</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensors</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">&gt;</span>, <span class="stt">axis</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Concatenates each <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> in <span class="pyret-highlight"><span class="stt">tensors</span></span> along the given
<span class="pyret-highlight"><span class="stt">axis</span></span>.</p><p>The <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s&rsquo; ranks and types must match, and their sizes must
match in all dimensions except <span class="pyret-highlight"><span class="stt">axis</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  concatenate([list: [tensor: 1], [tensor: 2]], 0).data-now()
    is-roughly [list: 1, 2]
  concatenate([list: [tensor: 1, 2, 3], [tensor: 4, 5, 6]], 0).data-now()
    is-roughly [list: 1, 2, 3, 4, 5, 6]

  two-dim-1 = [tensor: 1, 2, 3, 4].as-2d(2, 2)
  two-dim-2 = [tensor: 5, 6, 7, 8].as-2d(2, 2)

  concatenate([list: two-dim-1, two-dim-2], 0).data-now()
    is-roughly [list: 1, 2, 3, 4, 5, 6, 7, 8]
  concatenate([list: two-dim-1, two-dim-2], 1).data-now()
    is-roughly [list: 1, 2, 5, 6, 3, 4, 7, 8]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._689))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_gather)" class="pyret-code"></a><a href="#%28part._tensorflow_gather%29" data-pltdoc="x"><span class="stt">gather</span></a> :: (</dt><dt class="indent-arg"><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">indices</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">axis</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Gathers slices from the <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> at every index in <span class="pyret-highlight"><span class="stt">indices</span></span>
along the given <span class="pyret-highlight"><span class="stt">axis</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  input-1   = [tensor: 1, 2, 3, 4]
  indices-1 = [tensor: 1, 3, 3]

  gather(input-1, indices-1, none).data-now() is [list: 2, 4, 4]

  input-2   = [tensor: 1, 2, 3, 4].as-2d(2, 2)
  indices-2 = [tensor: 1, 1, 0]

  gather(input-2, indices-2, none).data-now() is [list: 3, 4,
                                                        3, 4,
                                                        1, 2]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._690))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reverse)" class="pyret-code"></a><a href="#%28part._tensorflow_reverse%29" data-pltdoc="x"><span class="stt">reverse</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axes</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Reverses the values in <span class="pyret-highlight"><span class="stt">tensor</span></span> along the specified <span class="pyret-highlight"><span class="stt">axis</span></span>.</p><p>If <span class="pyret-highlight"><span class="stt">axes</span></span> is <span class="pyret-highlight"><span class="stt">none</span></span>, the function defaults to reversing along
all axes.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  reverse([tensor: 0], none).data-now()
    is-roughly [list: 0]
  reverse([tensor: 1, 2], none).data-now()
    is-roughly [list: 2, 1]
  reverse([tensor: 1, 2, 3, 4, 5], none).data-now()
    is-roughly [list: 5, 4, 3, 2, 1]

  two-dim = [tensor: 1, 2, 3, 4, 5, 6].as-2d(3, 2)

  reverse(two-dim, none).data-now()
    is-roughly [list: 6, 5, 4, 3, 2, 1]
  reverse(two-dim, some([list: 0])).data-now()
    is-roughly [list: 5, 6, 3, 4, 1, 2]
  reverse(two-dim, some([list: 1])).data-now()
    is-roughly [list: 2, 1, 4, 3, 6, 5]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._691))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_slice)" class="pyret-code"></a><a href="#%28part._tensorflow_slice%29" data-pltdoc="x"><span class="stt">slice</span></a> :: (</dt><dt class="indent-arg"><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">begin</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">size</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Extracts a slice from <span class="pyret-highlight"><span class="stt">tensor</span></span> starting at the coordinates represented
by <span class="pyret-highlight"><span class="stt">begin</span></span>. The resulting slice is of size <span class="pyret-highlight"><span class="stt">size</span></span>.</p><p>A value of <span class="pyret-highlight"><span class="stt">-1</span></span> in <span class="pyret-highlight"><span class="stt">size</span></span> means that the resulting slice will go
all the way to the end of the dimensions in the respective axis.</p><p>If the length of <span class="pyret-highlight"><span class="stt">size</span></span> is less than the rank of in <span class="pyret-highlight"><span class="stt">tensor</span></span>, the
size of the rest of the axes will be implicitly set to <span class="pyret-highlight"><span class="stt">-1</span></span>. If
<span class="pyret-highlight"><span class="stt">size</span></span> is <span class="pyret-highlight"><span class="stt">none</span></span>, the size of all axes will be set to <span class="pyret-highlight"><span class="stt">-1</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  slice([tensor: 1], [list: 0], none).data-now()
    is-roughly [list: 1]
  slice([tensor: 1, 2, 3, 4, 5], [list: 2], none).data-now()
    is-roughly [list: 3, 4, 5]

  two-dim = [tensor: 1, 2, 3, 4, 5, 6].as-2d(3, 2)
  slice(two-dim, [list: 2, 1], none).data-now()
    is-roughly [list: 6]
  slice(two-dim, [list: 1, 0], none).data-now()
    is-roughly [list: 3, 4, 5, 6]

  slice(two-dim, [list: 2], none)
    raises "number of coordinates to start the slice at must be equal to the rank"

  slice(two-dim, [list: 1, 0], some([list: 2, 1])).data-now()
    is-roughly [list: 3, 5]
  slice(two-dim, [list: 1, 0], some([list: 1, 2])).data-now()
    is-roughly [list: 3, 4]

  slice(two-dim, [list: 1, 0], some([list: 1]))
    raises "dimensions for the size of the slice at must be equal to the rank"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._692))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_split)" class="pyret-code"></a><a href="#%28part._tensorflow_split%29" data-pltdoc="x"><span class="stt">split</span></a> :: (</dt><dt class="indent-arg"><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">split-sizes</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">axis</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">&gt;</span></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Splits <span class="pyret-highlight"><span class="stt">tensor</span></span> into sub-<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s along the specified
<span class="pyret-highlight"><span class="stt">axis</span></span>.</p><p><span class="pyret-highlight"><span class="stt">split-sizes</span></span> represents the sizes of each output Tensor along the
axis. The sum of the sizes in <span class="pyret-highlight"><span class="stt">split-sizes</span></span> must be equal to
<span class="pyret-highlight"><span class="stt">tensor.shape().get-value(axis)</span></span>; otherwise, an error will be raised.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim = split([tensor: 1, 2, 3, 4], [list: 1, 1, 2], 0)

  one-dim.length() is 3
  one-dim.get(0).data-now() is-roughly [list: 1]
  one-dim.get(1).data-now() is-roughly [list: 2]
  one-dim.get(2).data-now() is-roughly [list: 3, 4]

  split([tensor: 1, 2, 3, 4], [list: 1], 0)
    raises "sum of split sizes must match the size of the dimension"
  split([tensor: 1, 2, 3, 4], [list: 1, 1, 1, 1, 1], 0)
    raises "sum of split sizes must match the size of the dimension"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._693))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_stack)" class="pyret-code"></a><a href="#%28part._tensorflow_stack%29" data-pltdoc="x"><span class="stt">stack</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensors</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">&gt;</span>, <span class="stt">axis</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Stacks a list of rank-<span class="pyret-highlight"><span class="stt">R</span></span> <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s into one
rank-<span class="pyret-highlight"><span class="stt">(R + 1)</span></span> <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> along the specified <span class="pyret-highlight"><span class="stt">axis</span></span>.</p><p>Every <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> in <span class="pyret-highlight"><span class="stt">tensors</span></span> must have the same shape and
data type; otherwise, the function raises an error.</p><p>If <span class="pyret-highlight"><span class="stt">axis</span></span> is <span class="pyret-highlight"><span class="stt">none</span></span>, the operation will split along the first
dimension (axis 0) by default.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  stack([list: [tensor: 1]], 0).data-now()
    is-roughly [list: 1]
  stack([list: [tensor: 1], [tensor: 2]], 0).data-now()
    is-roughly [list: 1, 2]
  stack([list: [tensor: 1, 2], [tensor: 3, 4], [tensor: 5, 6]], 0).data-now()
    is-roughly [list: 1, 2, 3, 4, 5, 6]

  stack(empty, 0).data-now()
    raises "At least one Tensor must be supplied"
  stack([list: [tensor: 1]], 1)
    raises "Axis must be within the bounds of the Tensor"
  stack([list: [tensor: 1], [tensor: 2, 3], [tensor: 4]], 0)
    raises "All tensors passed to `stack` must have matching shapes"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._694))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_tile)" class="pyret-code"></a><a href="#%28part._tensorflow_tile%29" data-pltdoc="x"><span class="stt">tile</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">repetitions</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs a new <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> by repeating <span class="pyret-highlight"><span class="stt">tensor</span></span> the number
of times given by <span class="pyret-highlight"><span class="stt">repetitions</span></span>. Each number in <span class="pyret-highlight"><span class="stt">repetitions</span></span>
represents the number of replications in each dimension; that is, the first
element in the list represents the number of replications along the first
dimension, and so on.</p><p><a name="(idx._(gentag._695))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_unstack)" class="pyret-code"></a><a href="#%28part._tensorflow_unstack%29" data-pltdoc="x"><span class="stt">unstack</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">axis</span><span class="stt"> :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Unstacks a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> of rank-<span class="pyret-highlight"><span class="stt">R</span></span> into a <span class="pyret-highlight"><span class="stt">List</span></span> of
rank-<span class="pyret-highlight"><span class="stt">(R - 1)</span></span> <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s along the specified <span class="pyret-highlight"><span class="stt">axis</span></span>.</p><p>If <span class="pyret-highlight"><span class="stt">axis</span></span> is <span class="pyret-highlight"><span class="stt">none</span></span>, the operation will split along the first
dimension (axis 0) by default.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  unstack([tensor: 1], 0).map({(x): x.data-now()})
    is-roughly [list: [list: 1]]
  unstack([tensor: 1, 2], 0).map({(x): x.data-now()})
    is-roughly [list: [list: 1], [list: 2]]
  unstack([tensor: 1, 2, 3, 4], 0).map({(x): x.data-now()})
    is-roughly [list: [list: 1], [list: 2], [list: 3], [list: 4]]

  unstack([tensor: 1].as-scalar(), 0)
    raises "Tensor to be unstacked must be at least rank-1, but was rank-0"

  unstack([tensor: 1, 2, 3, 4], 1)
    raises "axis at which to unstack the Tensor must be within the bounds"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._696))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_strided-slice)" class="pyret-code"></a><a href="#%28part._tensorflow_strided-slice%29" data-pltdoc="x"><span class="stt">strided-slice</span></a> :: (</dt><dt class="indent-arg"><span class="stt">tensor</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">begin</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">end</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">strides</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Extracts a strided slice of a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>.</p><p>Roughly speaking, this operations extracts a slice of size
<span class="pyret-highlight"><span class="stt">(end - begin) / stride</span></span> from <span class="pyret-highlight"><span class="stt">tensor</span></span>. Starting at the location
specified by <span class="pyret-highlight"><span class="stt">begin</span></span>, the slice continues by adding <span class="pyret-highlight"><span class="stt">stride</span></span> to
the index until all dimensions are not less than <span class="pyret-highlight"><span class="stt">end</span></span>. Note that a
stride can be negative, which causes a reverse slice.</p><h5>3.28.3<tt>&nbsp;</tt><a name="(part._.Tensor.Buffers)"></a>TensorBuffers</h5><p><div class="SIntrapara"><a name="(idx._(gentag._697))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Tensor.Buffer)" class="pyret-code"></a><a href="#%28part._tensorflow_.Tensor.Buffer%29" data-pltdoc="x"><span class="stt">TensorBuffer</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">TensorBuffer</span>s are mutable objects that allow users to set values
at specific locations before converting the buffer into an immutable
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>.</div></p><p><a name="(idx._(gentag._698))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-tensor-buffer)" class="pyret-code"></a><a href="#%28part._tensorflow_is-tensor-buffer%29" data-pltdoc="x"><span class="stt">is-tensor-buffer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">TensorBuffer</span>; otherwise,
returns <span class="pyret-highlight"><span class="stt">false</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  is-tensor-buffer(make-buffer([list: 1])) is true
  is-tensor-buffer(make-buffer([list: 8, 4, 10])) is true
  is-tensor-buffer(43) is false
  is-tensor-buffer("not a buffer") is false
  is-tensor-buffer({some: "thing"}) is false
end</p></pre></pre></div></p></div><h5>3.28.3.1<tt>&nbsp;</tt><a name="(part._.Tensor.Buffer_.Constructors)"></a>TensorBuffer Constructors</h5><p><a name="(idx._(gentag._699))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-buffer)" class="pyret-code"></a><a href="#%28part._tensorflow_make-buffer%29" data-pltdoc="x"><span class="stt">make-buffer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor.Buffer%29" data-pltdoc="x"><span class="stt">TensorBuffer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates an <span class="stt">TensorBuffer</span> with the specified <span class="pyret-highlight"><span class="stt">shape</span></span>. The
returned <span class="stt">TensorBuffer</span>&rsquo;s values are initialized to <span class="pyret-highlight"><span class="stt">~0</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-buffer([list: 1]).size() is 1
  make-buffer([list: 1]).shape() is [list: 1]
  make-buffer([list: 9, 5]).size() is 45
  make-buffer([list: 9, 5]).shape() is [list: 9, 5]

  # Check for error handling of rank-0 shapes:
  make-buffer(empty) raises "input shape List had zero elements"

  # Check for error handling of less than zero dimension sizes:
  make-buffer([list: 0]) raises "Cannot create TensorBuffer"
  make-buffer([list: -1]) raises "Cannot create TensorBuffer"
  make-buffer([list: 4, 5, 0, 3]) raises "Cannot create TensorBuffer"
  make-buffer([list: 2, -5, -1, 4]) raises "Cannot create TensorBuffer"
end</p></pre></pre></div></p></div><h5>3.28.3.2<tt>&nbsp;</tt><a name="(part._.Tensor.Buffer_.Methods)"></a>TensorBuffer Methods</h5><p><a name="(idx._(gentag._700))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_size)" class="pyret-code"></a><span class="stt">.size</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns the size of the <span class="stt">TensorBuffer</span> (the number of values stored
in the <span class="stt">TensorBuffer</span>).</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-buffer([list: 1]).size() is 1
  make-buffer([list: 4]).size() is 4
  make-buffer([list: 3, 2]).size() is 6
  make-buffer([list: 4, 4]).size() is 16
  make-buffer([list: 4, 3, 5]).size() is 60
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._701))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_shape)" class="pyret-code"></a><span class="stt">.shape</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Returns a <span class="pyret-highlight"><span class="stt">List&lt;NumInteger&gt;</span></span> representing the shape of the
<span class="stt">TensorBuffer</span>. Each element in the <span class="pyret-highlight"><span class="stt">List&lt;NumInteger&gt;</span></span>
corresponds to the size in each dimension.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  make-buffer([list: 1]).shape() is [list: 1]
  make-buffer([list: 4, 3]).shape() is [list: 4, 3]
  make-buffer([list: 2, 4, 1]).shape() is [list: 2, 4, 1]
  make-buffer([list: 4, 3, 5]).shape() is [list: 4, 3, 5]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._702))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_set-now)" class="pyret-code"></a><span class="stt">.set-now</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">value</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a>, <span class="stt">indices</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Nothing%29" data-pltdoc="x"><span class="stt">Nothing</span></a></div><div class="description"></div><div class="examples"></div></div><p>Sets the value in the <span class="stt">TensorBuffer</span> at the specified <span class="pyret-highlight"><span class="stt">indicies</span></span>
to <span class="pyret-highlight"><span class="stt">value</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  test-buffer = make-buffer([list: 7])
  test-buffer.set-now(-45, [list: 0])
  test-buffer.set-now(9, [list: 2])
  test-buffer.set-now(0, [list: 4])
  test-buffer.set-now(-3.42, [list: 6])

  test-buffer.get-all-now() is-roughly [list: -45, 0, 9, 0, 0, 0, -3.42]
  test-buffer.to-tensor().shape() is [list: 7]
  test-buffer.to-tensor().data-now() is-roughly [list: -45, 0, 9, 0, 0, 0, -3.42]

  # Check out-of-bounds coordinates:
  test-buffer.set-now(10, [list: -1])
    raises "Coordinates must be within the bounds of the TensorBuffer's shape"
  test-buffer.set-now(10, [list: 8])
    raises "Coordinates must be within the bounds of the TensorBuffer's shape"

  # Check too little coordinates:
  test-buffer.set-now(10, [list:])
    raises "number of supplied coordinates must match the rank"

  # Check too many coordinates:
  test-buffer.set-now(10, [list: 9, 5])
    raises "number of supplied coordinates must match the rank"
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._703))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_get-now)" class="pyret-code"></a><span class="stt">.get-now</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">indices</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns the value in the <span class="stt">TensorBuffer</span> at the specified
<span class="pyret-highlight"><span class="stt">indicies</span></span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  test-buffer = make-buffer([list: 7])
  test-buffer.set-now(-45, [list: 0])
  test-buffer.set-now(9, [list: 2])
  test-buffer.set-now(0, [list: 4])
  test-buffer.set-now((4 / 3), [list: 5])
  test-buffer.set-now(-3.42, [list: 6])

  test-buffer.get-now([list: 0]) is-roughly -45
  test-buffer.get-now([list: 1]) is-roughly 0
  test-buffer.get-now([list: 2]) is-roughly 9
  test-buffer.get-now([list: 3]) is-roughly 0
  test-buffer.get-now([list: 4]) is-roughly 0
  test-buffer.get-now([list: 5]) is-roughly (4 / 3)
  test-buffer.get-now([list: 6]) is-roughly -3.42
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._704))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_get-all-now)" class="pyret-code"></a><span class="stt">.get-all-now</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Roughnum%29" data-pltdoc="x"><span class="stt">Roughnum</span></a><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Returns all values in the <span class="stt">TensorBuffer</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim-buffer = make-buffer([list: 7])
  one-dim-buffer.set-now(-45, [list: 0])
  one-dim-buffer.set-now(9, [list: 2])
  one-dim-buffer.set-now(0, [list: 4])
  one-dim-buffer.set-now((4 / 3), [list: 5])
  one-dim-buffer.set-now(-3.42, [list: 6])
  one-dim-buffer.get-all-now() is-roughly [list: -45, 0, 9, 0, 0, (4 / 3), -3.42]

  two-dim-buffer = make-buffer([list: 2, 2])
  two-dim-buffer.set-now(4, [list: 0, 0])
  two-dim-buffer.set-now(3, [list: 0, 1])
  two-dim-buffer.set-now(2, [list: 1, 0])
  two-dim-buffer.set-now(1, [list: 1, 1])
  two-dim-buffer.get-all-now() is-roughly [list: 4, 3, 2, 1]
end</p></pre></pre></div></p></div><p><a name="(idx._(gentag._705))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Tensor.Buffer_shared._methods_to-tensor)" class="pyret-code"></a><span class="stt">.to-tensor</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates an immutable <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> from the <span class="stt">TensorBuffer</span>.</p><div class="examples"><p><div class="SIntrapara"><span style="font-weight: bold">Examples:</span></div><div class="SIntrapara"><pre class="pyret-block"><pre class="pyret-highlight"><p>check:
  one-dim-buffer = make-buffer([list: 7])
  one-dim-buffer.set-now(-45, [list: 0])
  one-dim-buffer.set-now(9, [list: 2])
  one-dim-buffer.set-now(0, [list: 4])
  one-dim-buffer.set-now(-3.42, [list: 6])
  one-dim-buffer.to-tensor().shape() is [list: 7]
  one-dim-buffer.to-tensor().data-now() is-roughly [list: -45, 0, 9, 0, 0, 0, -3.42]

  two-dim-buffer = make-buffer([list: 2, 2])
  two-dim-buffer.set-now(4, [list: 0, 0])
  two-dim-buffer.set-now(3, [list: 0, 1])
  two-dim-buffer.set-now(2, [list: 1, 0])
  two-dim-buffer.set-now(1, [list: 1, 1])
  two-dim-buffer.to-tensor().shape() is [list: 2, 2]
  two-dim-buffer.to-tensor().data-now() is-roughly [list: 4, 3, 2, 1]
end</p></pre></pre></div></p></div><h5>3.28.4<tt>&nbsp;</tt><a name="(part._.Models)"></a>Models</h5><p><span class="stt">Model</span>s represent a collection of <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s, and define a
series of inputs and outputs. They are one of the primary abstractions used
in TensorFlow, and can be trained, evaluated, and used for prediction.</p><p>There are two types of models in TensorFlow: <a href="#%28part._tensorflow_.Sequential%29" data-pltdoc="x"><span class="stt">Sequential</span></a>, where
the outputs of one <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> are the inputs to the next
<a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>, and <a href="#%28part._tensorflow_.Model%29" data-pltdoc="x"><span class="stt">Model</span></a>, which is more generic and
supports arbitrary, non-cyclic graphs of <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s.</p><h5>3.28.4.1<tt>&nbsp;</tt><a name="(part._.Generic_.Models)"></a>Generic Models</h5><p><div class="SIntrapara"><a name="(idx._(gentag._706))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Model)" class="pyret-code"></a><a href="#%28part._tensorflow_.Model%29" data-pltdoc="x"><span class="stt">Model</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <span class="stt">Model</span> is a data structure that consists of <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s and
defines inputs and outputs. It is more generic than <a href="#%28part._tensorflow_.Sequential%29" data-pltdoc="x"><span class="stt">Sequential</span></a>
models as it supports arbitrary, non-cyclic graphs of <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s.</div></p><p><a name="(idx._(gentag._707))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-model)" class="pyret-code"></a><a href="#%28part._tensorflow_is-model%29" data-pltdoc="x"><span class="stt">is-model</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">Model</span>; otherwise, returns
<span class="pyret-highlight"><span class="stt">false</span></span>.</p><p><a name="(idx._(gentag._708))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-model)" class="pyret-code"></a><a href="#%28part._tensorflow_make-model%29" data-pltdoc="x"><span class="stt">make-model</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Model%29" data-pltdoc="x"><span class="stt">Model</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new generic <span class="stt">Model</span>.</p><h5>3.28.4.2<tt>&nbsp;</tt><a name="(part._.Sequential_.Models)"></a>Sequential Models</h5><p><div class="SIntrapara"><a name="(idx._(gentag._709))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Sequential)" class="pyret-code"></a><a href="#%28part._tensorflow_.Sequential%29" data-pltdoc="x"><span class="stt">Sequential</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <span class="stt">Sequential</span> model is a model where the outputs of one
<a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> are the inputs to the next <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>. That is,
the model topology is a simple "stack" of layers, with no branching or
skipping.</div></p><p>As a result, the first <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> passed to a <span class="stt">Sequential</span> model
must have a defined input shape. This means that the
<a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> used to instantiate the first <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>
must have a defined <span class="stt">input-shape</span> or <span class="stt">batch-input-shape</span> parameter.</p><p><a name="(idx._(gentag._710))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-sequential)" class="pyret-code"></a><a href="#%28part._tensorflow_is-sequential%29" data-pltdoc="x"><span class="stt">is-sequential</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">Sequential</span>; otherwise,
returns <span class="pyret-highlight"><span class="stt">false</span></span>.</p><p><a name="(idx._(gentag._711))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-sequential)" class="pyret-code"></a><a href="#%28part._tensorflow_make-sequential%29" data-pltdoc="x"><span class="stt">make-sequential</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Sequential%29" data-pltdoc="x"><span class="stt">Sequential</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">Sequential</span> model.</p><p><a name="(idx._(gentag._712))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Sequential_shared._methods_add)" class="pyret-code"></a><span class="stt">.add</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">layer</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Nothing%29" data-pltdoc="x"><span class="stt">Nothing</span></a></div><div class="description"></div><div class="examples"></div></div><p>Adds a <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> on top of the <span class="stt">Sequential</span>&rsquo;s stack.</p><p><a name="(idx._(gentag._713))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Sequential_shared._methods_compile)" class="pyret-code"></a><span class="stt">.compile</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Nothing%29" data-pltdoc="x"><span class="stt">Nothing</span></a></div><div class="description"></div><div class="examples"></div></div><p>Configures and prepares the <span class="stt">Sequential</span> model for training and
evaluation.</p><p>Compiling outfits the <span class="stt">Sequential</span> with an optimizer, loss, and/or
metrics. Calling <a href="#%28part._tensorflow_.Sequential_shared._methods_fit%29" data-pltdoc="x"><span class="stt">.fit</span></a> or
Calling <a href="#%28part._tensorflow_.Sequential_shared._methods_evaluate%29" data-pltdoc="x"><span class="stt">.evaluate</span></a> on an un-compiled model will
raise an error.</p><p><a name="(idx._(gentag._714))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_.Sequential_shared._methods_evaluate)" class="pyret-code"></a><span class="stt">.evaluate</span> :: (</dt><dt class="indent-arg"><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">y</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Returns the loss value &amp; metrics values for the model in test mode.</p><p>Loss and metrics parameters should be specified in a call to
<a href="#%28part._tensorflow_.Sequential_shared._methods_compile%29" data-pltdoc="x"><span class="stt">.compile</span></a> before calling this method.</p><p><a name="(idx._(gentag._715))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Sequential_shared._methods_predict)" class="pyret-code"></a><span class="stt">.predict</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>, <span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Generates output predictions for the input samples.</p><p>Computation is done in batches.</p><p><a name="(idx._(gentag._716))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Sequential_shared._methods_predict-on-batch)" class="pyret-code"></a><span class="stt">.predict-on-batch</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns predictions for a single batch of samples.</p><p><a name="(idx._(gentag._717))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_.Sequential_shared._methods_fit)" class="pyret-code"></a><span class="stt">.fit</span> :: (</dt><dt class="indent-arg"><span class="stt">x</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">y</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">config</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">epoch-callback</span><span class="stt"> :: </span><span class="stt">(</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">, </span><a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Nothing%29" data-pltdoc="x"><span class="stt">Nothing</span></a><span class="stt">)</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Nothing%29" data-pltdoc="x"><span class="stt">Nothing</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p><h5>3.28.5<tt>&nbsp;</tt><a name="(part._.Symbolic.Tensors)"></a>SymbolicTensors</h5><p><div class="SIntrapara"><a name="(idx._(gentag._718))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Symbolic.Tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_.Symbolic.Tensor%29" data-pltdoc="x"><span class="stt">SymbolicTensor</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">SymbolicTensor</span>s are placeholders for <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>s without
any concrete value.</div></p><p>They are most often encountered when building a graph of <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s
for a <a href="#%28part._tensorflow_.Model%29" data-pltdoc="x"><span class="stt">Model</span></a> that takes in some kind of unknown input.</p><p><a name="(idx._(gentag._719))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-symbolic-tensor)" class="pyret-code"></a><a href="#%28part._tensorflow_is-symbolic-tensor%29" data-pltdoc="x"><span class="stt">is-symbolic-tensor</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">SymbolicTensor</span>; otherwise,
returns <span class="pyret-highlight"><span class="stt">false</span></span>.</p><h5>3.28.5.1<tt>&nbsp;</tt><a name="(part._.Symbolic.Tensor_.Constructors)"></a>SymbolicTensor Constructors</h5><p><a name="(idx._(gentag._720))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-input)" class="pyret-code"></a><a href="#%28part._tensorflow_make-input%29" data-pltdoc="x"><span class="stt">make-input</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Symbolic.Tensor%29" data-pltdoc="x"><span class="stt">SymbolicTensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">SymbolicTensor</span> with the input shape, not including the
batch size.</p><p><span class="pyret-highlight"><span class="stt">none</span></span> values in the input <span class="pyret-highlight"><span class="stt">List</span></span> represent dimensions of
arbitrary length.</p><p><a name="(idx._(gentag._721))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_make-batch-input)" class="pyret-code"></a><a href="#%28part._tensorflow_make-batch-input%29" data-pltdoc="x"><span class="stt">make-batch-input</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">batch-shape</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Symbolic.Tensor%29" data-pltdoc="x"><span class="stt">SymbolicTensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a new <span class="stt">SymbolicTensor</span> with the input shape, where the first
element in the input <span class="pyret-highlight"><span class="stt">List</span></span> is the batch size.</p><p><span class="pyret-highlight"><span class="stt">none</span></span> values in the input <span class="pyret-highlight"><span class="stt">List</span></span> represent dimensions of
arbitrary length.</p><h5>3.28.5.2<tt>&nbsp;</tt><a name="(part._.Symbolic.Tensor_.Methods)"></a>SymbolicTensor Methods</h5><p><a name="(idx._(gentag._722))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Symbolic.Tensor_shared._methods_shape)" class="pyret-code"></a><span class="stt">.shape</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a><span class="stt">&gt;</span><span class="stt">&gt;</span></div><div class="description"></div><div class="examples"></div></div><p>Returns the shape of the <span class="stt">SymbolicTensor</span>. <span class="pyret-highlight"><span class="stt">none</span></span> values in the
output <span class="pyret-highlight"><span class="stt">List</span></span> represent dimensions of arbitrary length.</p><h5>3.28.6<tt>&nbsp;</tt><a name="(part._.Layers)"></a>Layers</h5><p><div class="SIntrapara"><a name="(idx._(gentag._723))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Layer)" class="pyret-code"></a><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">Layer</span>s are the primary building block for constructing a
<a href="#%28part._tensorflow_.Model%29" data-pltdoc="x"><span class="stt">Model</span></a>. Each <span class="stt">Layer</span> will typically perform some
computation to transform its input to its output.</div></p><p><span class="stt">Layer</span>s will automatically take care of creating and initializing
the various internal variables/weights they need to function.</p><p><a name="(idx._(gentag._724))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_is-layer%29" data-pltdoc="x"><span class="stt">is-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is a <span class="stt">Layer</span>; otherwise,
returns <span class="pyret-highlight"><span class="stt">false</span></span>.</p><h5>3.28.6.1<tt>&nbsp;</tt><a name="(part._.Layer-.Specific_.Datatypes)"></a>Layer-Specific Datatypes</h5><p><div class="SIntrapara"><a name="(idx._(gentag._725))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Layer.Config)" class="pyret-code"></a><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">LayerConfig</span>s are used to construct <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>s.</div></p><p>A <span class="stt">LayerConfig</span> is an <a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a> that describes
the properties of a <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>.</p><p>Every <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> can allow for different options in the
<span class="stt">LayerConfig</span> used to construct them. Those options are specified
underneath each <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a> constructor. Additionally, the
following options are permitted in every <span class="stt">LayerConfig</span>:</p><ul><li><p><span class="stt">input-shape :: List&lt;NumInteger&gt;</span>. Defines the input shape for
the first layer of a model. This argument is only applicable to input
layers (the first layer of a model). Only one of <span class="stt">input-shape</span> or
<span class="stt">batch-input-shape</span> should be defined.</p></li><li><p><span class="stt">batch-input-shape :: List&lt;NumInteger&gt;</span>. Defines the batch
  input shape for the first layer of a model. This argument is only
  applicable to input layers (the first layer of a model). Only one of
  <span class="stt">input-shape</span> or <span class="stt">batch-input-shape</span> should be defined.</p></li><li><p><span class="stt">batch-size :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. If
<span class="stt">input-shape</span> is specified, <span class="stt">batch-size</span> is used to construct
the <span class="stt">batch-input-shape</span> in the form
<span class="pyret-highlight"><span class="stt">[list: batch-size, ...input-shape]</span></span>.</p></li><li><p><span class="stt">trainable :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a>. Whether this layer
is trainable.</p></li><li><p><span class="stt">updatable :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a>. Whether the
weights of this layer are updatable by a call to
<a href="#%28part._tensorflow_.Sequential_shared._methods_fit%29" data-pltdoc="x"><span class="stt">.fit</span></a>.</p></li></ul><p>All options allowed in a given <a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a>&rsquo;s <span class="stt">LayerConfig</span> are
optional unless otherwise stated.</p><p><div class="SIntrapara"><a name="(idx._(gentag._726))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Activation)" class="pyret-code"></a><a href="#%28part._tensorflow_.Activation%29" data-pltdoc="x"><span class="stt">Activation</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow activation
function. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"elu"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"hardSigmoid"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"linear"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"relu"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"relu6"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"selu"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"sigmoid"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"softmax"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"softplus"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"softsign"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"tanh"</span></span></p></li></ul><p><div class="SIntrapara"><a name="(idx._(gentag._727))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Initializer)" class="pyret-code"></a><a href="#%28part._tensorflow_.Initializer%29" data-pltdoc="x"><span class="stt">Initializer</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow
initialization method. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"constant"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"glorotNormal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"glorotUniform"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"heNormal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"identity"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"leCunNormal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"ones"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"orthogonal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"randomNormal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"randomUniform"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"truncatedNormal"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"varianceScaling"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"zeros"</span></span></p></li></ul><p><div class="SIntrapara"><a name="(idx._(gentag._728))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Constraint)" class="pyret-code"></a><a href="#%28part._tensorflow_.Constraint%29" data-pltdoc="x"><span class="stt">Constraint</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow
constraint function. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"maxNorm"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"minMaxNorm"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"nonNeg"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"unitNorm"</span></span></p></li></ul><p><div class="SIntrapara"><a name="(idx._(gentag._729))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Regularizer)" class="pyret-code"></a><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow
regularizer function. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"l1l2"</span></span></p></li></ul><p><div class="SIntrapara"><a name="(idx._(gentag._730))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Data.Format)" class="pyret-code"></a><a href="#%28part._tensorflow_.Data.Format%29" data-pltdoc="x"><span class="stt">DataFormat</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow
tensor data format. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"channelsFirst"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"channelsLast"</span></span></p></li></ul><p><div class="SIntrapara"><a name="(idx._(gentag._731))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Padding.Method)" class="pyret-code"></a><a href="#%28part._tensorflow_.Padding.Method%29" data-pltdoc="x"><span class="stt">PaddingMethod</span></a><span class="stt"></span></div></div><div class="SIntrapara">A <a href="_global_.html#%28part._~3cglobal~3e_.String%29" data-pltdoc="x"><span class="stt">String</span></a> that specifies a TensorFlow
padding method. The following strings are options:</div></p><ul><li><p><span class="pyret-highlight"><span class="stt">"valid"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"same"</span></span></p></li><li><p><span class="pyret-highlight"><span class="stt">"casual"</span></span></p></li></ul><h5>3.28.6.2<tt>&nbsp;</tt><a name="(part._.Basic_.Layers)"></a>Basic Layers</h5><p><a name="(idx._(gentag._732))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_activation-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_activation-layer%29" data-pltdoc="x"><span class="stt">activation-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies an element-wise activation function to an output.</p><p>Other layers, most notably <a href="#%28part._tensorflow_dense-layer%29" data-pltdoc="x"><span class="stt">dense-layer</span></a>s, can also apply
activation functions. This <span class="stt">Layer</span> can be used to extract the values
before and after the activation.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">activation :: </span><a href="#%28part._tensorflow_.Activation%29" data-pltdoc="x"><span class="stt">Activation</span></a>. Defines the activation
function to apply in this <span class="stt">Layer</span>.</p></li></ul><p><a name="(idx._(gentag._733))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_dense-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_dense-layer%29" data-pltdoc="x"><span class="stt">dense-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Creates a dense (fully-connected) <span class="stt">Layer</span>.</p><p>This <span class="stt">Layer</span> implements the operation
<span class="pyret-highlight"><span class="stt">output = activation(dot(input, kernel) + bias)</span></span>, where
<span class="pyret-highlight"><span class="stt">activation</span></span> is the element-wise activation function passed as the
<span class="stt">activation</span> argument, <span class="pyret-highlight"><span class="stt">kernel</span></span> is a weights matrix created by the
<span class="stt">Layer</span>, and <span class="pyret-highlight"><span class="stt">bias</span></span> is a bias vector created by the layer if the
<span class="stt">use-bias</span> option is set to <span class="pyret-highlight"><span class="stt">true</span></span>.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">units :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> A positive integer specifying the dimensionality of the
output space.</p></li><li><p><span class="stt">activation :: </span><a href="#%28part._tensorflow_.Activation%29" data-pltdoc="x"><span class="stt">Activation</span></a>. Defines the activation
function to apply in this <span class="stt">Layer</span>.</p></li><li><p><span class="stt">use-bias :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a>. Whether to apply a
bias vector.</p></li><li><p><span class="stt">kernel-initializer :: </span><a href="#%28part._tensorflow_.Initializer%29" data-pltdoc="x"><span class="stt">Initializer</span></a>. Initializer for
the dense kernel weights matrix.</p></li><li><p><span class="stt">bias-initializer :: </span><a href="#%28part._tensorflow_.Initializer%29" data-pltdoc="x"><span class="stt">Initializer</span></a>. Initializer for the
bias vector.</p></li><li><p><span class="stt">input-dim :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. If specified,
defines <span class="stt">input-shape</span> as <span class="pyret-highlight"><span class="stt">[list: input-dim]</span></span>.</p></li><li><p><span class="stt">kernel-constraint :: </span><a href="#%28part._tensorflow_.Constraint%29" data-pltdoc="x"><span class="stt">Constraint</span></a>. Constraint for
the kernel weights matrix.</p></li><li><p><span class="stt">bias-constraint :: </span><a href="#%28part._tensorflow_.Constraint%29" data-pltdoc="x"><span class="stt">Constraint</span></a>. Constraint for the
bias vector.</p></li><li><p><span class="stt">kernel-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer function
applied to the dense kernel weights matrix.</p></li><li><p><span class="stt">bias-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer function
applied to the bias vector.</p></li><li><p><span class="stt">activity-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer
function applied to the activation.</p></li></ul><p><a name="(idx._(gentag._734))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_dropout-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_dropout-layer%29" data-pltdoc="x"><span class="stt">dropout-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Applies dropout to the input.</p><p>Dropout consists of randomly setting a fraction rate of input units to 0 at
each update during training time, which helps prevent overfitting. See
<a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a> for more
information.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">rate :: </span><a href="numbers.html#%28part._numbers_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a>. <span style="font-weight: bold">Required parameter.</span>
Denotes the fraction of the input units to drop; must be between
<span class="pyret-highlight"><span class="stt">0</span></span> and <span class="pyret-highlight"><span class="stt">1</span></span>.</p></li><li><p><span class="stt">noise-shape :: List&lt;NumInteger&gt;</span>. Integer array representing the
shape of the binary dropout mask that will be multiplied with the input.</p><p>For instance, if your inputs have shape
<span class="pyret-highlight"><span class="stt">[list: batch-size, timesteps, features]</span></span> and you want the dropout
mask to be the same for all timesteps, you can set
<span class="stt">noise_shape</span> to <span class="pyret-highlight"><span class="stt">[list: batch-size, 1, features]</span></span>.</p></li><li><p><span class="stt">seed :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. An integer to use as
random seed.</p></li></ul><p><a name="(idx._(gentag._735))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_embedding-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_embedding-layer%29" data-pltdoc="x"><span class="stt">embedding-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Maps positive integers (indices) into dense vectors of fixed size.</p><p>The input shape of this layer is a two-dimensional <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>
with shape <span class="pyret-highlight"><span class="stt">[list: batch-size, sequence-length]</span></span>.</p><p>The output shape of this layer is a three-dimensional <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a>
with shape <span class="pyret-highlight"><span class="stt">[list: batch-size, sequence-length, output-dim]</span></span>.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">input-dim :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> Must also be a <a href="numbers.html#%28part._numbers_.Num.Positive%29" data-pltdoc="x"><span class="stt">NumPositive</span></a>. Denotes
the size of the vocabulary; that is, the maximum integer index + 1.</p></li><li><p><span class="stt">output-dim :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> Must also be a <a href="numbers.html#%28part._numbers_.Num.Non.Negative%29" data-pltdoc="x"><span class="stt">NumNonNegative</span></a>.
Dimension of the dense embedding.</p></li><li><p><span class="stt">embeddings-initializer :: </span><a href="#%28part._tensorflow_.Initializer%29" data-pltdoc="x"><span class="stt">Initializer</span></a>. Initializer for
embeddings matrix.</p></li><li><p><span class="stt">embeddings-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer function
applied to the embeddings matrix.</p></li><li><p><span class="stt">activity-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer
function applied to the activation.</p></li><li><p><span class="stt">embeddings-constraint :: </span><a href="#%28part._tensorflow_.Constraint%29" data-pltdoc="x"><span class="stt">Constraint</span></a>. Constraint
applied to the embeddings matrix.</p></li><li><p><span class="stt">mask-zero :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a>. Whether the input
value <span class="pyret-highlight"><span class="stt">0</span></span> is a special "padding" value that should be masked out.
This is useful when using recurrent layers which may take variable
length input.</p><p>If set to <span class="pyret-highlight"><span class="stt">true</span></span>, then all subsequent layers in the model need to
support masking or an exception will be raised. Additionally, if
<span class="stt">mask-zero</span> is set to <span class="pyret-highlight"><span class="stt">true</span></span>, as a consequence, index <span class="pyret-highlight"><span class="stt">0</span></span>
cannot be used in the vocabulary (that is, <span class="stt">input-dim</span> should equal
the size the of vocabulary + 1).</p></li><li><p><span class="stt">input-length :: List&lt;NumInteger&gt;</span>. Length of input sequences, when it
is constant.</p><p>This argument is required if you are going to connect
<a href="#%28part._tensorflow_flatten-layer%29" data-pltdoc="x"><span class="stt">flatten-layer</span></a>s then <a href="#%28part._tensorflow_dense-layer%29" data-pltdoc="x"><span class="stt">dense-layer</span></a>s upstream,
since otherwise the shape of the dense outputs cannot be computed.</p></li></ul><p><a name="(idx._(gentag._736))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_flatten-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_flatten-layer%29" data-pltdoc="x"><span class="stt">flatten-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Flattens the input. Does not affect the batch size.</p><p>A <a href="#%28part._tensorflow_flatten-layer%29" data-pltdoc="x"><span class="stt">flatten-layer</span></a> flattens each batch in its inputs to one
dimension (making the output two dimensional).</p><p>The <span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor does not support any
additional options other than the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options.</p><p><a name="(idx._(gentag._737))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_repeat-vector-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_repeat-vector-layer%29" data-pltdoc="x"><span class="stt">repeat-vector-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Repeats the input <span class="stt">num-repeats</span> times in a new dimension.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">num-repeats :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> Must also be a <a href="numbers.html#%28part._numbers_.Num.Positive%29" data-pltdoc="x"><span class="stt">NumPositive</span></a>.
Represents the number of times to repeat the input.</p></li></ul><p><a name="(idx._(gentag._738))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_reshape-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_reshape-layer%29" data-pltdoc="x"><span class="stt">reshape-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Reshapes an input to a certain shape.</p><p>The input shape can be arbitrary, although all dimensions in the input shape
must be fixed.</p><p>The output shape is
<span class="pyret-highlight"><span class="stt">[list: batch-size, target-shape.get(0), ..., target-shape.get(i)]</span></span>.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">target-shape :: List&lt;NumInteger&gt;</span>. The target shape; should not
include the <span class="stt">batch-size</span>.</p></li></ul><h5>3.28.6.3<tt>&nbsp;</tt><a name="(part._.Convolutional_.Layers)"></a>Convolutional Layers</h5><p><a name="(idx._(gentag._739))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_conv-1d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_conv-1d-layer%29" data-pltdoc="x"><span class="stt">conv-1d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>A one-dimensional convolution <span class="stt">Layer</span>.</p><p>This layer creates a convolution kernel that is convolved with the layer
input over a single spatial (or temporal) dimension to produce a
<a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> of outputs.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">filters :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> The dimensionality of the output space; that is, the number
of filters in the convolution.</p></li></ul><p><a name="(idx._(gentag._740))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_conv-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_conv-2d-layer%29" data-pltdoc="x"><span class="stt">conv-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>A two-dimensional convolution <span class="stt">Layer</span>.</p><p>This layer creates a convolution kernel that is convolved with the layer
input to produce a <a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a> of outputs.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">filters :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> The dimensionality of the output space; that is, the number
of filters in the convolution.</p></li></ul><p><a name="(idx._(gentag._741))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_conv-2d-transpose-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_conv-2d-transpose-layer%29" data-pltdoc="x"><span class="stt">conv-2d-transpose-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Transposed convolutional <span class="stt">Layer</span>. This is sometimes known as a
"deconvolution" layer.</p><p>The need for transposed convolutions generally arises from the desire to
use a transformation going in the opposite direction of a normal
convolution; for example, from something that has the shape of the output
of some convolution to something that has the shape of its input while
maintaining a connectivity pattern that is compatible with said convolution.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">filters :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. <span style="font-weight: bold">Required
parameter.</span> The dimensionality of the output space; that is, the number
of filters in the convolution.</p></li></ul><p><a name="(idx._(gentag._742))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_cropping-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_cropping-2d-layer%29" data-pltdoc="x"><span class="stt">cropping-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Crops an two-dimensional input at the top, bottom, left, and right side
(for example, image data).</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">cropping :: {top-crop :: NumInteger, bottom-crop :: NumInteger,
left-crop :: NumInteger, right-crop :: NumInteger}</span>. <span style="font-weight: bold">Required
parameter.</span> An <a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a> that specifies the
cropping along each side of the width and the height.</p></li><li><p><span class="stt">data-format :: </span><a href="#%28part._tensorflow_.Data.Format%29" data-pltdoc="x"><span class="stt">DataFormat</span></a>. Format of the data, which
determines the ordering of the dimensions in the inputs.</p></li></ul><p><a name="(idx._(gentag._743))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_depthwise-conv-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_depthwise-conv-2d-layer%29" data-pltdoc="x"><span class="stt">depthwise-conv-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Depthwise separable two-dimensional convolution.</p><p>A depthwise separable convolution consists of performing just the first
step in a depthwise spatial convolution (which acts on each input channel
separately). The <span class="stt">depth-multiplier</span> argument controls how many output
channels are generated per input channel in the depthwise step.</p><p>In addition to the default <a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a> options, the
<span class="pyret-highlight"><span class="stt">config</span></span> passed to this constructor can also contain:</p><ul><li><p><span class="stt">kernel-size :: {width :: NumInteger, height :: NumInteger}</span>.
<span style="font-weight: bold">Required parameter.</span> An <a href="_global_.html#%28part._~3cglobal~3e_.Object%29" data-pltdoc="x"><span class="stt">Object</span></a> that
specifies the width and height of the two-dimensional convolution
window.</p></li><li><p><span class="stt">depth-multiplier :: </span><a href="numbers.html#%28part._numbers_.Num.Integer%29" data-pltdoc="x"><span class="stt">NumInteger</span></a>. The number
of depthwise convolution output channels for each input channel.</p></li><li><p><span class="stt">depthwise-initializer :: </span><a href="#%28part._tensorflow_.Initializer%29" data-pltdoc="x"><span class="stt">Initializer</span></a>. Initializer for
the depthwise kernel matrix.</p></li><li><p><span class="stt">depthwise-constraint :: </span><a href="#%28part._tensorflow_.Constraint%29" data-pltdoc="x"><span class="stt">Constraint</span></a>. Constraint for
the depthwise kernel matrix.</p></li><li><p><span class="stt">depthwise-regularizer :: </span><a href="#%28part._tensorflow_.Regularizer%29" data-pltdoc="x"><span class="stt">Regularizer</span></a>. Regularizer function
applied to the depthwise kernel matrix.</p></li></ul><p><a name="(idx._(gentag._744))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_separable-conv-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_separable-conv-2d-layer%29" data-pltdoc="x"><span class="stt">separable-conv-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._745))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_up-sampling-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_up-sampling-2d-layer%29" data-pltdoc="x"><span class="stt">up-sampling-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.6.4<tt>&nbsp;</tt><a name="(part._.Merge_.Layers)"></a>Merge Layers</h5><p><a name="(idx._(gentag._746))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_add-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_add-layer%29" data-pltdoc="x"><span class="stt">add-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._747))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_average-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_average-layer%29" data-pltdoc="x"><span class="stt">average-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._748))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_concatenate-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_concatenate-layer%29" data-pltdoc="x"><span class="stt">concatenate-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._749))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_maximum-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_maximum-layer%29" data-pltdoc="x"><span class="stt">maximum-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._750))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_minimum-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_minimum-layer%29" data-pltdoc="x"><span class="stt">minimum-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._751))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_multiply-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_multiply-layer%29" data-pltdoc="x"><span class="stt">multiply-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.6.5<tt>&nbsp;</tt><a name="(part._.Normalization_.Layers)"></a>Normalization Layers</h5><p><a name="(idx._(gentag._752))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_batch-normalization-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_batch-normalization-layer%29" data-pltdoc="x"><span class="stt">batch-normalization-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.6.6<tt>&nbsp;</tt><a name="(part._.Pooling_.Layers)"></a>Pooling Layers</h5><p><a name="(idx._(gentag._753))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_average-pooling-1d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_average-pooling-1d-layer%29" data-pltdoc="x"><span class="stt">average-pooling-1d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._754))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_average-pooling-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_average-pooling-2d-layer%29" data-pltdoc="x"><span class="stt">average-pooling-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._755))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_global-average-pooling-1d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_global-average-pooling-1d-layer%29" data-pltdoc="x"><span class="stt">global-average-pooling-1d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._756))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_global-average-pooling-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_global-average-pooling-2d-layer%29" data-pltdoc="x"><span class="stt">global-average-pooling-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._757))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_global-max-pooling-1d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_global-max-pooling-1d-layer%29" data-pltdoc="x"><span class="stt">global-max-pooling-1d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._758))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_global-max-pooling-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_global-max-pooling-2d-layer%29" data-pltdoc="x"><span class="stt">global-max-pooling-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._759))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_max-pooling-1d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_max-pooling-1d-layer%29" data-pltdoc="x"><span class="stt">max-pooling-1d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._760))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_max-pooling-2d-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_max-pooling-2d-layer%29" data-pltdoc="x"><span class="stt">max-pooling-2d-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.6.7<tt>&nbsp;</tt><a name="(part._.Recurrent_.Layers)"></a>Recurrent Layers</h5><p><a name="(idx._(gentag._761))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_gru-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_gru-layer%29" data-pltdoc="x"><span class="stt">gru-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._762))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_gru-cell-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_gru-cell-layer%29" data-pltdoc="x"><span class="stt">gru-cell-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._763))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_lstm-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_lstm-layer%29" data-pltdoc="x"><span class="stt">lstm-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._764))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_lstm-cell-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_lstm-cell-layer%29" data-pltdoc="x"><span class="stt">lstm-cell-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._765))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_rnn-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_rnn-layer%29" data-pltdoc="x"><span class="stt">rnn-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._766))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_simple-rnn-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_simple-rnn-layer%29" data-pltdoc="x"><span class="stt">simple-rnn-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._767))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_simple-rnn-cell-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_simple-rnn-cell-layer%29" data-pltdoc="x"><span class="stt">simple-rnn-cell-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._768))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_stacked-rnn-cells-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_stacked-rnn-cells-layer%29" data-pltdoc="x"><span class="stt">stacked-rnn-cells-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.6.8<tt>&nbsp;</tt><a name="(part._.Wrapper_.Layers)"></a>Wrapper Layers</h5><p><a name="(idx._(gentag._769))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_bidirectional-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_bidirectional-layer%29" data-pltdoc="x"><span class="stt">bidirectional-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><p><a name="(idx._(gentag._770))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_time-distributed-layer)" class="pyret-code"></a><a href="#%28part._tensorflow_time-distributed-layer%29" data-pltdoc="x"><span class="stt">time-distributed-layer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">config</span><span class="stt"> :: </span><a href="#%28part._tensorflow_.Layer.Config%29" data-pltdoc="x"><span class="stt">LayerConfig</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Layer%29" data-pltdoc="x"><span class="stt">Layer</span></a></div><div class="description"></div><div class="examples"></div></div><h5>3.28.7<tt>&nbsp;</tt><a name="(part._.Optimizers)"></a>Optimizers</h5><p><div class="SIntrapara"><a name="(idx._(gentag._771))"></a></div><div class="SIntrapara"><div class="boxed"><a name="(part._tensorflow_.Optimizer)" class="pyret-code"></a><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a><span class="stt"></span></div></div><div class="SIntrapara"><span class="stt">Optimizer</span>s are used to perform training operations and compute
gradients.</div></p><p><span class="stt">Optimizer</span>s eagerly compute gradients. This means that when a user
provides a function that is a combination of TensorFlow operations
to an <span class="stt">Optimizer</span>, the <span class="stt">Optimizer</span> automatically differentiates
that function&rsquo;s output with respect to its inputs.</p><p><a name="(idx._(gentag._772))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_is-optimizer)" class="pyret-code"></a><a href="#%28part._tensorflow_is-optimizer%29" data-pltdoc="x"><span class="stt">is-optimizer</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">val</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Any%29" data-pltdoc="x"><span class="stt">Any</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></div><div class="description"></div><div class="examples"></div></div><p>Returns <span class="pyret-highlight"><span class="stt">true</span></span> if <span class="pyret-highlight"><span class="stt">val</span></span> is an <span class="stt">Optimizer</span>; otherwise,
returns <span class="pyret-highlight"><span class="stt">false</span></span>.</p><h5>3.28.7.1<tt>&nbsp;</tt><a name="(part._.Optimizer_.Constructors)"></a>Optimizer Constructors</h5><p>There are many different types of <span class="stt">Optimizer</span>s that use different
formulas to compute gradients.</p><p><a name="(idx._(gentag._773))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_train-sgd)" class="pyret-code"></a><a href="#%28part._tensorflow_train-sgd%29" data-pltdoc="x"><span class="stt">train-sgd</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses a stochastic gradient descent
algorithm, where <span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for the
algorithm.</p><p><a name="(idx._(gentag._774))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_train-momentum)" class="pyret-code"></a><a href="#%28part._tensorflow_train-momentum%29" data-pltdoc="x"><span class="stt">train-momentum</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a>, <span class="stt">momentum</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses a momentum gradient descent
algorithm, where <span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for the
algorithm and <span class="pyret-highlight"><span class="stt">momentum</span></span> is the momentum to use for the algorithm.</p><p>See <a href="http://proceedings.mlr.press/v28/sutskever13.pdf">http://proceedings.mlr.press/v28/sutskever13.pdf</a>.</p><p><a name="(idx._(gentag._775))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_train-adagrad)" class="pyret-code"></a><a href="#%28part._tensorflow_train-adagrad%29" data-pltdoc="x"><span class="stt">train-adagrad</span></a><span class="stt"> :: </span><span class="stt">(</span><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a>, <span class="stt">initial-accumulator</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="numbers.html#%28part._numbers_.Num.Positive%29" data-pltdoc="x"><span class="stt">NumPositive</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses the Adagrad algorithm, where
<span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for the Adagrad gradient
descent algorithm.</p><p>If not <span class="pyret-highlight"><span class="stt">none</span></span>, <span class="pyret-highlight"><span class="stt">initial-accumulator</span></span> is the positive, starting
value for the accumulators in the Adagrad algorithm. If
<span class="pyret-highlight"><span class="stt">initial-accumulator</span></span> is specified but is not positive, the function
raises an error.</p><p>See <a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf</a> or
<a href="http://ruder.io/optimizing-gradient-descent/index.html#adagrad">http://ruder.io/optimizing-gradient-descent/index.html#adagrad</a>.</p><p><a name="(idx._(gentag._776))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_train-adadelta)" class="pyret-code"></a><a href="#%28part._tensorflow_train-adadelta%29" data-pltdoc="x"><span class="stt">train-adadelta</span></a> :: (</dt><dt class="indent-arg"><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">rho</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">epsilon</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses the Adadelta algorithm.</p><p>If not <span class="pyret-highlight"><span class="stt">none</span></span>, <span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for
the Adamax gradient descent algorithm, <span class="pyret-highlight"><span class="stt">rho</span></span> is the learning rate
decay over each update, and <span class="pyret-highlight"><span class="stt">epsilon</span></span> is a constant used to better
condition the gradient updates.</p><p>See <a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a>.</p><p><a name="(idx._(gentag._777))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_train-adam)" class="pyret-code"></a><a href="#%28part._tensorflow_train-adam%29" data-pltdoc="x"><span class="stt">train-adam</span></a> :: (</dt><dt class="indent-arg"><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">beta-1</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">beta-2</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">epsilon</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses the Adam algorithm.</p><p>If not <span class="pyret-highlight"><span class="stt">none</span></span>, <span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for
the Adamax gradient descent algorithm, <span class="pyret-highlight"><span class="stt">beta-1</span></span> is the exponential
decay rate for the first moment estimates, <span class="pyret-highlight"><span class="stt">beta-2</span></span> is the
exponential decay rate for the second moment estimates, and
<span class="pyret-highlight"><span class="stt">epsilon</span></span> is a small constant for numerical stability.</p><p>See <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>.</p><p><a name="(idx._(gentag._778))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_train-adamax)" class="pyret-code"></a><a href="#%28part._tensorflow_train-adamax%29" data-pltdoc="x"><span class="stt">train-adamax</span></a> :: (</dt><dt class="indent-arg"><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">beta-1</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">beta-2</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">epsilon</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">decay</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses the Adamax algorithm.</p><p>If not <span class="pyret-highlight"><span class="stt">none</span></span>, <span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for
the Adamax gradient descent algorithm, <span class="pyret-highlight"><span class="stt">beta-1</span></span> is the exponential
decay rate for the first moment estimates, <span class="pyret-highlight"><span class="stt">beta-2</span></span> is the
exponential decay rate for the second moment estimates, <span class="pyret-highlight"><span class="stt">epsilon</span></span> is
a small constant for numerical stability, and <span class="pyret-highlight"><span class="stt">decay</span></span> is the learning
rate decay over each update.</p><p>See <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>.</p><p><a name="(idx._(gentag._779))"></a></p><div class="function"><div class="boxed pyret-header"><dl class="multiline-args"><dt class=""><a name="(part._tensorflow_train-rmsprop)" class="pyret-code"></a><a href="#%28part._tensorflow_train-rmsprop%29" data-pltdoc="x"><span class="stt">train-rmsprop</span></a> :: (</dt><dt class="indent-arg"><span class="stt">learning-rate</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">decay</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">momentum</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">epsilon</span><span class="stt"> :: </span><a href="option.html#%28part._option_.Option%29" data-pltdoc="x"><span class="stt">Option</span></a><span class="stt">&lt;</span><a href="_global_.html#%28part._~3cglobal~3e_.Number%29" data-pltdoc="x"><span class="stt">Number</span></a><span class="stt">&gt;</span><span class="stt">,</span></dt><dd class=""></dd><dt class="indent-arg"><span class="stt">is-centered</span><span class="stt"> :: </span><a href="_global_.html#%28part._~3cglobal~3e_.Boolean%29" data-pltdoc="x"><span class="stt">Boolean</span></a></dt><dd class=""></dd><dt class=""><span class="stt">)</span></dt><dt class=""><span class="stt">-&gt; </span><a href="#%28part._tensorflow_.Optimizer%29" data-pltdoc="x"><span class="stt">Optimizer</span></a></dt></dl></div><div class="description"></div><div class="examples"></div></div><p>Constructs an <span class="stt">Optimizer</span> that uses RMSProp gradient descent, where
<span class="pyret-highlight"><span class="stt">learning-rate</span></span> is the learning rate to use for the RMSProp gradient
descent algorithm.</p><p>If not <span class="pyret-highlight"><span class="stt">none</span></span>, <span class="pyret-highlight"><span class="stt">decay</span></span> represents the discounting factor for the
history/coming gradient, <span class="pyret-highlight"><span class="stt">momentum</span></span> represents the momentum to use for
the RMSProp gradient descent algorithm, and <span class="pyret-highlight"><span class="stt">epsilon</span></span> is a small value
to avoid division-by-zero errors.</p><p>If <span class="pyret-highlight"><span class="stt">is-centered</span></span> is <span class="pyret-highlight"><span class="stt">true</span></span>, gradients are normalized by the
estimated varience of the gradient.</p><p>See <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">these slides from the University of Toronto</a> for a primer on RMSProp.</p><p><span style="font-weight: bold">Note:</span> This TensorFlow.js implementation uses plain momentum and is
not the "centered" version of RMSProp.</p><h5>3.28.7.2<tt>&nbsp;</tt><a name="(part._.Optimizer_.Methods)"></a>Optimizer Methods</h5><p><a name="(idx._(gentag._780))"></a></p><div class="function"><div class="boxed pyret-header"><a name="(part._tensorflow_.Optimizer_shared._methods_minimize)" class="pyret-code"></a><span class="stt">.minimize</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt">f</span><span class="stt"> :: </span><span class="stt">(</span><span class="stt"></span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">)</span>, <span class="stt">variables</span><span class="stt"> :: </span><a href="lists.html#%28part._lists_.List%29" data-pltdoc="x"><span class="stt">List</span></a><span class="stt">&lt;</span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a><span class="stt">&gt;</span><span class="stt">)</span><span class="stt"> -&gt; </span><a href="#%28part._tensorflow_.Tensor%29" data-pltdoc="x"><span class="stt">Tensor</span></a></div><div class="description"></div><div class="examples"></div></div><p>Executes <span class="pyret-highlight"><span class="stt">f</span></span> and minimizes the scalar output of <span class="pyret-highlight"><span class="stt">f</span></span> by computing
gradients of <span class="pyret-highlight"><span class="stt">y</span></span> with with respect to the list of trainable, variable
<span class="stt">Tensor</span>s provided by <span class="pyret-highlight"><span class="stt">variables</span></span>.</p><p><span class="pyret-highlight"><span class="stt">f</span></span> must be a thunk that returns a scalar <span class="stt">Tensor</span>.
The method then returns the scalar <span class="stt">Tensor</span> produced by <span class="pyret-highlight"><span class="stt">f</span></span>.</p><p>If <span class="pyret-highlight"><span class="stt">variables</span></span> is <span class="pyret-highlight"><span class="stt">empty</span></span>, the <span class="stt">Optimizer</span> will default
to training all trainable variables that have been instantiated.</p><div class="navsetbottom"><span class="navleft"><form class="searchform"><input class="searchbox" style="color: #888;" type="text" value="...search manuals..." title="Enter a search string to search the manuals" onkeypress="return DoSearchKey(event, this, &quot;6.12&quot;, &quot;&quot;);" onfocus="this.style.color=&quot;black&quot;; this.style.textAlign=&quot;left&quot;; if (this.value == &quot;...search manuals...&quot;) this.value=&quot;&quot;;" onblur="if (this.value.match(/^ *$/)) { this.style.color=&quot;#888&quot;; this.style.textAlign=&quot;center&quot;; this.value=&quot;...search manuals...&quot;; }"/></form>&nbsp;&nbsp;</span><span class="navright">&nbsp;&nbsp;<a href="math.html" title="backward to &quot;3.27 math&quot;" data-pltdoc="x">&larr; prev</a>&nbsp;&nbsp;<a href="Builtins_and_Libraries.html" title="up to &quot;3 Builtins and Libraries&quot;" data-pltdoc="x">up</a>&nbsp;&nbsp;<a href="Pyret_Style_Guide.html" title="forward to &quot;4 Pyret Style Guide&quot;" data-pltdoc="x">next &rarr;</a></span>&nbsp;</div></div></div><div id="contextindicator">&nbsp;</div></body></html>